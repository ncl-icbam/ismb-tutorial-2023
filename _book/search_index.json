[["index.html", "Spatial transcriptomics data analysis: theory and practice Welcome Abstract Learning objectives", " Spatial transcriptomics data analysis: theory and practice Eleftherios Zormpas, Dr Simon J. Cockell 2023-06-09 Welcome This book will guide you through the practical steps of the in-person tutorial IP2 for the ISMB/ECCB 2023 conference in Lyon named: “Spatial transcriptomics data analysis: theory and practice”. Abstract Recent technological advances have led to the application of RNA Sequencing in situ. This allows for whole-transcriptome characterisation, at approaching single-cell resolution, while retaining the spatial information inherent in the intact tissue. Since tissues are congregations of intercommunicating cells, identifying local and global patterns of spatial association is imperative to elucidate the processes which underlie tissue function. Performing spatial data analysis requires particular considerations of the distinct properties of data with a spatial dimension, which gives rise to an association with a different set of statistical and inferential considerations. In this comprehensive tutorial, we will introduce users to spatial transcriptomics (STx) technologies and current pipelines of STx data analysis inside the Bioconductor framework. Furthermore, we will introduce attendees to the underlying features of spatial data analysis and how they can effectively utilise space to extract in-depth information from STx datasets. Learning objectives Participants in this tutorial will gain understanding of the core technologies for undertaking a spatial transcriptomics experiment, and the common tools used for the analysis of this data. In particular, participants will appreciate the strengths of geospatial data analysis methods in relation to this type of data. Specific learning objectives will include: Describe and discuss core technologies for spatial transcriptomics Make use of key computational technologies to process and analyse STx data Apply an analysis strategy to obtain derived results and data visualisations Appreciate the principles underlying spatial data analysis Understand some of the methods available for spatial data analysis Apply said methods to an example STx data set "],["practical-session-1.html", "Chapter 1 Practical session 1 1.1 Log into the Posit Cloud server 1.2 Import 10X Visium data 1.3 Explore data types", " Chapter 1 Practical session 1 In this practical session you will familiarise yourself with the data and their different aspects. 1.1 Log into the Posit Cloud server 1.2 Import 10X Visium data In this tutorial we will be using some already prepared data from the STexampleData package. These data are stored in the SpatialExperiment format (the format is described below). The dataset a single sample from the dorsolateral prefrontal cortex (DLPFC) 10x Genomics Visium dataset, that was published by Maynard et al. (2021). Here, we show how to load the data from the STexampleData package. library(SpatialExperiment) library(STexampleData) # Load the object spe &lt;- Visium_humanDLPFC() 1.3 Explore data types The below discussion will help you familiarise with the different data types that we will be using. 1.3.1 SpatialExperiment class For the first part of this tutorial (practical sessions 1 and 2), we will be using the SpatialExperiment S4 class from Bioconductor as the main data structure for storing and manipulating datasets. SpatialExperiment is a specialized object class that supports the storing of spatially-resolved transcriptomics datasets within the Bioconductor framework. It builds on the SingleCellExperiment class (Amezquita et al. 2020) for single-cell RNA sequencing data. More specifically, has extra customisations to store spatial information (i.e., spatial coordinates and images). An overview of the SpatialExperiment object structure is is presented in Figure 2.1. In brief, the SpatialExperiment object consists of the below five parts: assays: gene expression counts rowData: information about features, usually genes colData: information on spots (non-spatial and spatial metadata) spatialCoords: spatial coordinates imgData: image data NOTE: For spot-based STx data (i.e., 10x Genomics Visium), a single assay named counts is used. Figure 1.1: Overview of the SpatialExperiment object class structure. For more details, see the related publication from Righelli et al., 2021 describing the SpatialExperiment (Righelli et al. 2022). 1.3.2 Inspect the object ## Check the object&#39;s structure spe ## class: SpatialExperiment ## dim: 33538 4992 ## metadata(0): ## assays(1): counts ## rownames(33538): ENSG00000243485 ENSG00000237613 ... ENSG00000277475 ## ENSG00000268674 ## rowData names(3): gene_id gene_name feature_type ## colnames(4992): AAACAACGAATAGTTC-1 AAACAAGTATCTCCCA-1 ... ## TTGTTTGTATTACACG-1 TTGTTTGTGTAAATTC-1 ## colData names(7): barcode_id sample_id ... ground_truth cell_count ## reducedDimNames(0): ## mainExpName: NULL ## altExpNames(0): ## spatialCoords names(2) : pxl_col_in_fullres pxl_row_in_fullres ## imgData names(4): sample_id image_id data scaleFactor ## Check number of features/genes (rows) and spots (columns) dim(spe) ## [1] 33538 4992 ## Check names of &#39;assay&#39; tables assayNames(spe) ## [1] &quot;counts&quot; 1.3.3 Counts table and gene metadata ## Have a look at the counts table assay(spe)[1:6,1:4] ## 6 x 4 sparse Matrix of class &quot;dgTMatrix&quot; ## AAACAACGAATAGTTC-1 AAACAAGTATCTCCCA-1 AAACAATCTACTAGCA-1 ## ENSG00000243485 . . . ## ENSG00000237613 . . . ## ENSG00000186092 . . . ## ENSG00000238009 . . . ## ENSG00000239945 . . . ## ENSG00000239906 . . . ## AAACACCAATAACTGC-1 ## ENSG00000243485 . ## ENSG00000237613 . ## ENSG00000186092 . ## ENSG00000238009 . ## ENSG00000239945 . ## ENSG00000239906 . As you can see here the counts table is of class dgTMatrix which is a sparse matrix. This is because much like scRNA-seq data, STx data are sparse and include many zeros. As a result, to make the counts table as light as possible we resort to using sparse matrices. The next code chunk will demonstrate a part of the matrix that includes genes with some level of expression. assay(spe)[20:40, 2000:2010] ## 21 x 11 sparse Matrix of class &quot;dgTMatrix&quot; ## ## ENSG00000223764 . . . . . . . . . . . ## ENSG00000187634 . . . . . . . . . . . ## ENSG00000188976 . . 2 . . . . . . 1 1 ## ENSG00000187961 . . . . . . . . . . . ## ENSG00000187583 . . . . . . . . . . . ## ENSG00000187642 . . . . . . . . . . . ## ENSG00000272512 . . . . . . . . . . . ## ENSG00000188290 1 . . . . . . . . 2 . ## ENSG00000187608 . 1 . . . . 2 . . 1 . ## ENSG00000224969 . . . . . . . . . . . ## ENSG00000188157 . 1 . . 2 . . . . 1 . ## ENSG00000273443 . . . . . . . . . . . ## ENSG00000237330 . . . . . . . . . . . ## ENSG00000131591 . . . . . . . . . 1 . ## ENSG00000223823 . . . . . . . . . . . ## ENSG00000272141 . . . . . . . . . . . ## ENSG00000205231 . . . . . . . . . . . ## ENSG00000162571 . . . . . . . . . . . ## ENSG00000186891 . . . 1 . . . . . . . ## ENSG00000186827 . . . . . . . . . . . ## ENSG00000078808 . 1 2 . 1 . . . . 1 . assay(spe)[33488:33508, 2000:2010] ## 21 x 11 sparse Matrix of class &quot;dgTMatrix&quot; ## ## ENSG00000160294 . . . . . . . . . . . ## ENSG00000228137 . . . . . . . . . . . ## ENSG00000239415 . . . . . . . . . . . ## ENSG00000182362 . . . . . . . . 1 . . ## ENSG00000160298 . . . . . . . . . . . ## ENSG00000160299 . . 1 . 1 . . . . . . ## ENSG00000160305 . . . . . 2 . . . . . ## ENSG00000160307 1 3 1 1 4 5 1 1 . 2 1 ## ENSG00000160310 . . . . 1 . . . . 2 . ## ENSG00000198888 17 44 71 16 154 97 12 14 32 167 6 ## ENSG00000198763 16 59 64 11 116 63 11 12 18 123 6 ## ENSG00000198804 37 85 155 25 252 176 24 27 38 335 12 ## ENSG00000198712 23 79 120 23 214 170 22 25 48 242 10 ## ENSG00000228253 2 . 3 . 1 . . 1 1 6 . ## ENSG00000198899 20 39 93 9 136 108 20 18 25 165 7 ## ENSG00000198938 27 59 133 20 216 120 22 26 43 232 9 ## ENSG00000198840 5 27 33 5 71 39 8 11 12 78 . ## ENSG00000212907 2 . 4 2 7 5 . 1 1 9 . ## ENSG00000198886 15 65 95 9 183 98 18 19 33 178 7 ## ENSG00000198786 2 10 10 3 20 14 1 2 2 25 4 ## ENSG00000198695 1 1 3 . 2 2 . . . 1 . As you can see, the levels of expression of different genes in the same spots differ significantly with many low values being present. We have to remember here that we look at un-normalised expression data which are affected by factors like library size. Nonetheless, this is a fact in STx data as it is for scRNA-seq data; many genes will show low expression in individual spots. ## Have a look at the genes metadata head(rowData(spe)) ## DataFrame with 6 rows and 3 columns ## gene_id gene_name feature_type ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000243485 ENSG00000243485 MIR1302-2HG Gene Expression ## ENSG00000237613 ENSG00000237613 FAM138A Gene Expression ## ENSG00000186092 ENSG00000186092 OR4F5 Gene Expression ## ENSG00000238009 ENSG00000238009 AL627309.1 Gene Expression ## ENSG00000239945 ENSG00000239945 AL627309.3 Gene Expression ## ENSG00000239906 ENSG00000239906 AL627309.2 Gene Expression 1.3.4 Coordinates table and spot metadata ## Check the spatial coordinates head(spatialCoords(spe)) ## pxl_col_in_fullres pxl_row_in_fullres ## AAACAACGAATAGTTC-1 3913 2435 ## AAACAAGTATCTCCCA-1 9791 8468 ## AAACAATCTACTAGCA-1 5769 2807 ## AAACACCAATAACTGC-1 4068 9505 ## AAACAGAGCGACTCCT-1 9271 4151 ## AAACAGCTTTCAGAAG-1 3393 7583 ## spot-level metadata head(colData(spe)) ## DataFrame with 6 rows and 7 columns ## barcode_id sample_id in_tissue array_row ## &lt;character&gt; &lt;character&gt; &lt;integer&gt; &lt;integer&gt; ## AAACAACGAATAGTTC-1 AAACAACGAATAGTTC-1 sample_151673 0 0 ## AAACAAGTATCTCCCA-1 AAACAAGTATCTCCCA-1 sample_151673 1 50 ## AAACAATCTACTAGCA-1 AAACAATCTACTAGCA-1 sample_151673 1 3 ## AAACACCAATAACTGC-1 AAACACCAATAACTGC-1 sample_151673 1 59 ## AAACAGAGCGACTCCT-1 AAACAGAGCGACTCCT-1 sample_151673 1 14 ## AAACAGCTTTCAGAAG-1 AAACAGCTTTCAGAAG-1 sample_151673 1 43 ## array_col ground_truth cell_count ## &lt;integer&gt; &lt;character&gt; &lt;integer&gt; ## AAACAACGAATAGTTC-1 16 NA NA ## AAACAAGTATCTCCCA-1 102 Layer3 6 ## AAACAATCTACTAGCA-1 43 Layer1 16 ## AAACACCAATAACTGC-1 19 WM 5 ## AAACAGAGCGACTCCT-1 94 Layer3 2 ## AAACAGCTTTCAGAAG-1 9 Layer5 4 1.3.5 Image metadata ## Have a look at the image metadata imgData(spe) ## DataFrame with 2 rows and 4 columns ## sample_id image_id data scaleFactor ## &lt;character&gt; &lt;character&gt; &lt;list&gt; &lt;numeric&gt; ## 1 sample_151673 lowres #### 0.0450045 ## 2 sample_151673 hires #### 0.1500150 References "],["practical-session-2.html", "Chapter 2 Practical session 2 2.1 Spot-level Quality Control 2.2 Normalisation of counts 2.3 Selecting genes 2.4 Dimensionality reduction 2.5 Clustering 2.6 Inter-cluster differentially expressed genes (DGEs) 2.7 Other visualisations 2.8 Putting it all together", " Chapter 2 Practical session 2 In this session we will demonstrate the implementation of the methods discussed earlier and will particularly focus on the most common analysis routines in STx: QC, data visualisation and clustering analysis always inside the interoperable Bioconductor environment. ## Load packages {-} library(ggspavis) library(ggplot2) library(scater) library(scran) library(igraph) library(pheatmap) ggspavis is a Bioconductor package that includes visualization functions for spatially resolved transcriptomics datasets stored in SpatialExperiment format from spot-based (e.g., 10x Genomics Visium) platforms (Weber and Crowell (2022)). scater is also a Bioconductor package that is a selection of tools for doing various analyses of scRNA-seq gene expression data, with a focus on quality control and visualization which has extended applications to STx data too. It is based on the SingleCellExperiment and SpatialExperiment classes and thus is interoperable with many other Bioconductor packages such as scran, scuttle and iSEE. 2.1 Spot-level Quality Control Spot-level quality control (sQC) procedures are employed to eliminate low-quality spots before conducting further analyses. Low-quality spots may result from issues during library preparation or other experimental procedures, such as a high percentage of dead cells due to cell damage during library preparation, or low mRNA capture efficiency caused by ineffective reverse transcription or PCR amplification. Keeping these spots usually leads to creating problems during downstream analyses. We can identify low-quality spots using several characteristics that are also used in QC for scRNA-sq data, including: library size (total of UMI counts per spot is going to be different due to sequencing -like different samples in a bulk RNA-seq- or due to number of cells in the spot) number of expressed genes (i.e. number of genes with non-zero UMI counts per spot) proportion of reads mapping to mitochondrial genes (a high proportion indicates putative cell damage) Low library size or low number of expressed features can indicate poor mRNA capture rates, e.g. due to cell damage and missing mRNAs, or low reaction efficiency. A high proportion of mitochondrial reads indicates cell damage, e.g. partial cell lysis leading to leakage and missing cytoplasmic mRNAs, with the resulting reads therefore concentrated on the remaining mitochondrial mRNAs that are relatively protected inside the mitochondrial membrane. Unusually high numbers of cells per spot can indicate problems during cell segmentation. The idea of using scRNA-seq QC metrics in STx data comes from the fact that if we remove space and count each spot as a single cell, the two datasets share common features. However, the expected distributions for high-quality spots are different (compared to high-quality cells in scRNA-seq), since spots may contain zero, one, or multiple cells. A few publications for further reading that can help you understand the quality controls: McCarthy et al. (2017) and Amezquita et al. (2020). 2.1.1 Plot tissue map The DLPFC dataset we will be using comes with manual annotations by the authors Maynard et al. (2021). We can plot the tissue map with and without the annotations to get a complete view. ## Plot spatial coordinates without annotations plotSpots(spe) ## Plot spatial coordinates with annotations plotSpots(spe, annotate = &quot;ground_truth&quot;) 2.1.2 Calculating QC metrics We will now calculate the three main QC metrics described above using methods from the scater (McCarthy et al. 2017) package and our own functions INSERT LINK OR CITATION HERE. So far, the dataset contains both on- and off-tissue spots. For the analysis though we are only interested in the on-tissue spots. Therefore, before we run any calculations we want to remove the off-tissue spots. NOTE: the on- or off-tissue information for each spot can be found in the colData of the spe object and in the in_tissue column where 0 = off-tissue and 1 = on-tissue. ## Dataset dimensions before the filtering dim(spe) ## [1] 33538 4992 ## Subset to keep only on-tissue spots spe &lt;- spe[, colData(spe)$in_tissue == 1] dim(spe) ## [1] 33538 3639 The next thing we need to do before we make decisions on how to quality “trim” the dataset is to calculate the percentage per spot of mitochodrial gene expression and store this information inside the colData. ## Fetch mitochondrial gene names is_mito &lt;- grepl(&quot;(^MT-)|(^mt-)&quot;, rowData(spe)$gene_name) rowData(spe)$gene_name[is_mito] ## [1] &quot;MT-ND1&quot; &quot;MT-ND2&quot; &quot;MT-CO1&quot; &quot;MT-CO2&quot; &quot;MT-ATP8&quot; &quot;MT-ATP6&quot; &quot;MT-CO3&quot; ## [8] &quot;MT-ND3&quot; &quot;MT-ND4L&quot; &quot;MT-ND4&quot; &quot;MT-ND5&quot; &quot;MT-ND6&quot; &quot;MT-CYB&quot; ## Calculate per-spot QC metrics and store in colData spe &lt;- addPerCellQC(spe, subsets = list(mito = is_mito)) head(colData(spe)) ## DataFrame with 6 rows and 13 columns ## barcode_id sample_id in_tissue array_row ## &lt;character&gt; &lt;character&gt; &lt;integer&gt; &lt;integer&gt; ## AAACAAGTATCTCCCA-1 AAACAAGTATCTCCCA-1 sample_151673 1 50 ## AAACAATCTACTAGCA-1 AAACAATCTACTAGCA-1 sample_151673 1 3 ## AAACACCAATAACTGC-1 AAACACCAATAACTGC-1 sample_151673 1 59 ## AAACAGAGCGACTCCT-1 AAACAGAGCGACTCCT-1 sample_151673 1 14 ## AAACAGCTTTCAGAAG-1 AAACAGCTTTCAGAAG-1 sample_151673 1 43 ## AAACAGGGTCTATATT-1 AAACAGGGTCTATATT-1 sample_151673 1 47 ## array_col ground_truth cell_count sum detected ## &lt;integer&gt; &lt;character&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; ## AAACAAGTATCTCCCA-1 102 Layer3 6 8458 3586 ## AAACAATCTACTAGCA-1 43 Layer1 16 1667 1150 ## AAACACCAATAACTGC-1 19 WM 5 3769 1960 ## AAACAGAGCGACTCCT-1 94 Layer3 2 5433 2424 ## AAACAGCTTTCAGAAG-1 9 Layer5 4 4278 2264 ## AAACAGGGTCTATATT-1 13 Layer6 6 4004 2178 ## subsets_mito_sum subsets_mito_detected subsets_mito_percent ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## AAACAAGTATCTCCCA-1 1407 13 16.6351 ## AAACAATCTACTAGCA-1 204 11 12.2376 ## AAACACCAATAACTGC-1 430 13 11.4089 ## AAACAGAGCGACTCCT-1 1316 13 24.2223 ## AAACAGCTTTCAGAAG-1 651 12 15.2174 ## AAACAGGGTCTATATT-1 621 13 15.5095 ## total ## &lt;numeric&gt; ## AAACAAGTATCTCCCA-1 8458 ## AAACAATCTACTAGCA-1 1667 ## AAACACCAATAACTGC-1 3769 ## AAACAGAGCGACTCCT-1 5433 ## AAACAGCTTTCAGAAG-1 4278 ## AAACAGGGTCTATATT-1 4004 After calculating the necessary metrics, we need to apply some cut-off thresholds for each metric to perform QC over each spot. What is important to remember here is that each dataset might need slightly different cut-off values to be applied. As a result we cannot rely on identifying a single value to use every time and we need to rely on plotting these metrics and making a decision on a dataset-by-dataset basis. 2.1.3 Library size threshold plot We can plot a histogram of the library sizes across spots. The library size is the number of UMI counts in each spot. We can find this information in the sum column in the colData. ## Density and histogram of library sizes ggplot(data = as.data.frame(colData(spe)), aes(x = sum)) + geom_histogram(aes(y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Library size&quot;) + ylab(&quot;Density&quot;) + theme_classic() As we can see there are no obvious issues with the library sizes. An example of an issue could be a high frequency of small libraries which would indicate poor experimental output. Generally we do not want to keep spots with too small libraries. If the dataset we are analysing contains the number of cells that are present in each spot (this one does), then it makes sense to also plot the library sizes against the number of cells per spot. In that way we are making sure that we don’t remove any spots that may have biological meaning. In many cases though the datasets do not have such information unless we can generate it using a nuclei segmentation tool to extract this information from the H&amp;E images. The horizontal red line (argument threshold in the plotQC function) shows a first guess at a possible filtering threshold for library size based on the above histogram. The below plot can also be plotted using ggplot. ## Scatter plot, library size against number of cells per spot plotQC(spe, type = &quot;scatter&quot;, metric_x = &quot;cell_count&quot;, metric_y = &quot;sum&quot;, threshold_y = 700) We need to keep in mind here that the threshold is, up to an extend, arbitrary. It is crucial, then, to have a look at the number of spots that are left out of the dataset because of this cut-off value and also have a look at their putative spatial patterns. If, by any chance, we filtered out spots with biological relevance, then we will observe some patterns on the tissue map that are correlating with some of the known biological structures of the tissue. As a result, we probably have set our threshold too high. ## Select library size threshold qc_lib_size &lt;- colData(spe)$sum &lt; 700 ## Check how many spots are filtered out table(qc_lib_size) ## qc_lib_size ## FALSE TRUE ## 3628 11 ## Add threshold in colData colData(spe)$qc_lib_size &lt;- qc_lib_size ## Check putative spatial patterns of removed spots plotQC(spe, type = &quot;spots&quot;, discard = &quot;qc_lib_size&quot;) As an aside, try to illustrate what happens if we set the threshold too high (i.e., 2000 UMI counts). NOTE: For reference, remember the ground truth layers in this dataset that we plotted at the beginning. ## Select library size threshold code... ## Check how many spots are filtered out code... ## Add threshold in colData code... ## Check putative spatial patterns of removed spots plotQC(...) 2.1.4 Number of expressed genes As we did with the library sizes, we can plot a histogram of the number of expressed genes across spots. A gene is expressed in a spot if it has at least one count in it. We can find this information in the detected column in the colData. We will follow the same logic for the plots as we did for the library size earlier. ## Density and histogram of expressed genes ggplot(data = as.data.frame(colData(spe)), aes(x = detected)) + geom_histogram(aes(y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Genes expressed in each spot&quot;) + ylab(&quot;Density&quot;) + theme_classic() # plot number of expressed genes vs. number of cells per spot plotQC(spe, type = &quot;scatter&quot;, metric_x = &quot;cell_count&quot;, metric_y = &quot;detected&quot;, threshold_y = 500) ## Select expressed genes threshold qc_detected &lt;- colData(spe)$detected &lt; 500 ## Check how many spots are filtered out table(qc_detected) ## qc_detected ## FALSE TRUE ## 3628 11 ## Add threshold in colData colData(spe)$qc_detected &lt;- qc_detected ## Check for putative spatial pattern of removed spots plotQC(spe, type = &quot;spots&quot;, discard = &quot;qc_detected&quot;) Again, try to illustrate what happens if we set the threshold too high (i.e., 1000 expressed genes). NOTE: For reference, remember the ground truth layers in this dataset that we plotted at the beginning. ## Select library size threshold code... ## Check how many spots are filtered out code... ## Add threshold in colData code... ## Check putative spatial patterns of removed spots plotQC(...) 2.1.5 Percentage of mitochondrial expression As we briefly touched at the beginning, a high proportion of mitochondrial reads indicates low cell quality, probably due to cell damage. To investigate the percentage of mitochondrial expression across spots we need to take a look in the column subsets_mito_percent in the colData. ## Density and histogram of percentage of mitochondrial expression ggplot(data = as.data.frame(colData(spe)), aes(x = subsets_mito_percent)) + geom_histogram(aes(y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Percentage of mitochondrial expression&quot;) + ylab(&quot;Density&quot;) + theme_classic() # plot mitochondrial read proportion vs. number of cells per spot plotQC(spe, type = &quot;scatter&quot;, metric_x = &quot;cell_count&quot;, metric_y = &quot;subsets_mito_percent&quot;, threshold_y = 28) ## Select expressed genes threshold qc_mito &lt;- colData(spe)$subsets_mito_percent &gt; 28 ## Check how many spots are filtered out table(qc_mito) ## qc_mito ## FALSE TRUE ## 3622 17 ## Add threshold in colData colData(spe)$qc_mito &lt;- qc_mito ## Check for putative spatial pattern of removed spots plotQC(spe, type = &quot;spots&quot;, discard = &quot;qc_mito&quot;) Again, try to illustrate what happens if we set the threshold too low (i.e., 20 0r 25%). NOTE: For reference, remember the ground truth layers in this dataset that we plotted at the beginning. ## Select library size threshold code... ## Check how many spots are filtered out code... ## Add threshold in colData code... ## Check putative spatial patterns of removed spots plotQC(...) 2.1.6 Number of cells per spot Number of cells per spot is an attribute that not all datasets include. Nonetheless, if it exists, we can use this information to further control the quality of the dataset prior to any downstream analysis. Ofcourse, the number of cells per spot depends on the tissue type and organism and according to 10X Genomics, each spot can contain between 0 and 10 cells. To investigate the number of cells in each spot looking for any outlier values that could indicate problems we need to take a look in the column cell_count in the colData. ## Density and histogram of the number of cells in each spot ggplot(data = as.data.frame(colData(spe)), aes(x = cell_count)) + geom_histogram(aes(y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(alpha = 0.5, adjust = 1.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of cells per spot&quot;) + ylab(&quot;Density&quot;) + theme_classic() ## Have a look at the values table(colData(spe)$cell_count) ## ## 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## 84 211 483 623 617 541 421 287 140 92 50 25 18 10 9 3 8 2 1 2 ## 20 21 22 23 25 26 27 ## 3 2 1 1 2 2 1 # plot number of expressed genes vs. number of cells per spot plotQC(spe, type = &quot;scatter&quot;, metric_x = &quot;cell_count&quot;, metric_y = &quot;detected&quot;, threshold_x = 10) As we can see from both the histogram and the scatter plot there is a tail of very high values, which could indicate problems for these spots. More specifically, we can see from the scatter plot that most of the spots with very high cell counts also have low numbers of expressed genes. This indicates problems with the experiment on these spots, and they should be removed. ## Select expressed genes threshold qc_cell_count &lt;- colData(spe)$cell_count &gt; 10 ## Check how many spots are filtered out table(qc_cell_count) ## qc_cell_count ## FALSE TRUE ## 3549 90 ## Add threshold in colData colData(spe)$qc_cell_count &lt;- qc_cell_count ## Check for putative spatial pattern of removed spots plotQC(spe, type = &quot;spots&quot;, discard = &quot;qc_cell_count&quot;) While there is a spatial pattern to the discarded spots, it does not appear to be correlated with the known biological features (cortical layers). The discarded spots are all on the edges of the tissue. It seems plausible that something has gone wrong with the cell segmentation on the edges of the images, so it makes sense to remove these spots. The discarded spots are located at the tissue edges, indicating a potential issue with cell segmentation in those regions. Therefore, it is reasonable to remove these spots from the analysis. 2.1.7 Remove low-quality spots Since we have calculated different spot-level QC metrics and selected thresholds for each one, we can combine them to identify a set of low-quality spots, and remove them from our spe object. We also check again that the combined set of discarded spots does not correspond to any obvious biologically relevant group of spots. ## Check the number of discarded spots for each metric apply(cbind(qc_lib_size, qc_detected, qc_mito, qc_cell_count), 2, sum) ## qc_lib_size qc_detected qc_mito qc_cell_count ## 11 11 17 90 ## Combine together the set of discarded spots discard &lt;- qc_lib_size | qc_detected | qc_mito | qc_cell_count ## Store the set in the object colData(spe)$discard &lt;- discard ## Check the spatial pattern of combined set of discarded spots plotQC(spe, type = &quot;spots&quot;, discard = &quot;discard&quot;) Since this dataset has also manual annotation (remember here) we see that there are locations that are not annotated (marked with NA). We could further remove those locations to reduce noise and further increase the quality of the dataset. ## Select locations without annotation qc_NA_spots &lt;- is.na(colData(spe)$ground_truth) ## Combine together the set of discarded spots discard &lt;- qc_lib_size | qc_detected | qc_mito | qc_cell_count | qc_NA_spots ## Store the set in the object colData(spe)$discard &lt;- discard ## Check the spatial pattern of combined set of discarded spots plotQC(spe, type = &quot;spots&quot;, discard = &quot;discard&quot;) ## remove combined set of low-quality spots spe &lt;- spe[, !colData(spe)$discard] 2.2 Normalisation of counts 2.2.1 Background The most common method (if not the only one so far) of normalising gene expression in STx data is the method used in scRNA-seq data. Namely, this is a log-transformation (logcounts). For this to be applied, we treat each spot as being a single cell. It is clear from what we discussed earlier that each spot can contain more than one cells. This is a limitation to the technology itself and to our methods of analysing STx data so far. Nonetheless, since STx expression data look like scRNA-seq we apply scRNA-seq methods for normalising (not all methods can be applied though). Here we will be using methods from the scater (McCarthy et al. 2017) and scran (Lun, McCarthy, and Marioni 2016) packages that calculate logcounts using library size factors. The library size factors approach is arguably the simplest approach for STx data. Other approaches used in scRNA-seq are more difficult to justify their use in STx because of two main reasons: Spots can contain multiple cells of different cell-types. Datasets can include multiple tissue samples which will lead to different clusterings. 2.2.2 Log-tranformation of counts ## Calculate library size factors spe &lt;- computeLibraryFactors(spe) ## Have a look at the size factors summary(sizeFactors(spe)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1514 0.6326 0.9011 1.0000 1.2849 3.7500 ## Density and histogram of library sizes ggplot(data = data.frame(sFact = sizeFactors(spe)), aes(x = sFact)) + geom_histogram(aes(y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Library size&quot;) + ylab(&quot;Density&quot;) + theme_classic() The log-transformation that takes place is a log2-transformation and in order to avoid - Infinity values we add a pseudo value of 1. Both the log2- transformation and the pseudocount of 1 are defaults in this method. ## Calculate logcounts and store in the spe object spe &lt;- logNormCounts(spe) ## Check that a new assay has been added assayNames(spe) ## [1] &quot;counts&quot; &quot;logcounts&quot; 2.3 Selecting genes 2.3.1 Background Gene selection -or alternatively “feature selection”- is applied to identify genes that are going to be informative and can produce valuable information form the downstream analyses. The most common way of applying gene selection is to select genes that are highly variable (HVGs). The assumption is that since we quality-controled and normalised our dataset, the genes with high variability are the ones that contain high levels of biological variability too. Since here we have a spatial dataset we can also try to identify spatially variable genes too (SVGs). What is important to note here is that HVGs are identified using features like gene expression. Spatial information does not play a role in finding HVGs. STx data pose a dilemma; does the meaningful spatial information reflects only spatial distribution of major cell types or reflects additional important spatial features? If the first is true, then, relying on HVGs can be enough. If the second also holds true, then, it is important to identify SVGs as well. 2.3.2 Highly Variable Genes (HVGs) Here we will be using methods from the scran package (Lun, McCarthy, and Marioni 2016) to identify a set of HVGs. Again, here we need to remember that scran methods were developed for scRNA-seq and we are performing the analysis under the assumption that the spots of an STx experiment can be treated as single cells. In this dataset, the mitochondrial genes are too highly expressed and are not of major biological interest. As a result, if we are to identify true HVGs, we first need to remove the mitochondrial genes. ## Remove mitochondrial genes spe &lt;- spe[!is_mito, ] Then, we apply methods from scran that give a list of HVGs, which can be used for further downstream analyses. First we model the variance of the log-expression profiles for each gene, decomposing it into technical and biological components based on a fitted mean-variance trend. ## Fit mean-variance relationship dec &lt;- modelGeneVar(spe) ## Visualize mean-variance relationship fit &lt;- metadata(dec) fit_df &lt;- data.frame(mean = fit$mean, var = fit$var, trend = fit$trend(fit$mean)) ggplot(data = fit_df, aes(x = mean, y = var)) + geom_point() + geom_line(aes(y = trend), colour = &quot;dodgerblue&quot;, linewidth = 1.5) + labs(x = &quot;mean of log-expression&quot;, y = &quot;variance of log-expression&quot;) + theme_classic() The trend function that we used above is returned from the modelGeneVar function and returns the fitted value of the trend at any value of the mean. We select the top 10% of genes based on their variability The parameter prop defines how many HVGs we want. For example prop = 0.1 returns the top 10% of genes. ## Select top HVGs top_hvgs &lt;- getTopHVGs(dec, prop = 0.1) ## How many are the HVGs? length(top_hvgs) ## [1] 1429 2.3.3 Spatially variable genes (SVGs) SVGs are genes with a highly spatially correlated pattern of expression, which varies along with the spatial distribution of a tissue structure of interest. This phenomenon is also called spatial autocorrelation and is a phenomenon that underlies all types of spatial data as we will discuss later. The field of geography has developed some statistical measures to calculate spatial autocorrelation. Examples of these are Moran’s I (“Notes on Continuous Stochastic Phenomena on JSTOR” 1950) and Geary’s C (“The Contiguity Ratio and Statistical Mapping on JSTOR” 1954) that can be used to rank genes by the observed spatial autocorrelation to identify SVGs. Several sophisticated new statistical methods to identify SVGs in SRT data have also recently been developed. These include SpatialDE (Svensson, Teichmann, and Stegle 2018), SPARK (Sun, Zhu, and Zhou 2020), and SPARK-X (Zhu, Sun, and Zhou 2021). 2.3.4 Integration of HVGs and SVGs A recent benchmark paper (Li et al. 2022) showed that integrating HVGs and SVGs to generate a combined set of features can improve downstream clustering performance in SRT data. This confirms that SVGs contain additional biologically relevant information that is not captured by HVGs in these datasets. For example, a simple way to combine these features is to concatenate columns of principal components (PCs) calculated on the set of HVGs and the set of SVGs (excluding overlapping HVGs), and then using the combined set of features for further downstream analyses (Li et al. 2022). 2.4 Dimensionality reduction 2.4.1 Background Dimensionality reduction is an important step prior to any downstream clustering attempts. There are two main ways of reducing the dimensions of a dataset. The gold standard is Principal Components Analysis (PCA) and the other -a more recent one- Uniform manifold Approximation and Projection (UMAP) (McInnes, Healy, and Melville 2018). The main difference between the two is that the distances between the data points in PCA space are interpretable and can be used to cluster the data points while the distances in a UMAP embedding are not interpretable and thus, cannot be used to cluster the data points. As a result, we will be using PCA to reduce the dimensions of our dataset to assist clustering and UMAP to further reduce the principal components (PCs) in a two-dimensional space and produce better visualisations for the PCA. Reducing the dimensions of the dataset is the output of a PCA. But, what are the main reasons we do so? One reason is to reduce the noise introduced by biologically uninteresting genes that their expression might show some random variation -and that is why they are in the HVGs list-. The other reason is to improve the computational efficiency of downstream analyses like clustering. In an STx experiment, like the one we are analysing here, we have more than 3000 spots and almost 1500 HVGs. As as result, each spot has 1500 attributes based on which the clustering will take place. This increase in the number of variables that differentiate or cluster together spots is leading to the curse of dimensionality (Keogh and Mueen 2017) which makes the data points (spots) look equidistant in attribute space resulting in poor clustering output. 2.4.2 PCA: Principal component analysis Here we will use an efficient implementation of PCA provided in the scater package (McCarthy et al. 2017) and retain the top 50 PCs for further downstream analyses. The random seed is required for reproducibility reasons because this implementation uses randomisation. ## Set seed set.seed(987) ## Compute PCA spe &lt;- runPCA(spe, subset_row = top_hvgs) ## Check correctness - names reducedDimNames(spe) ## [1] &quot;PCA&quot; ## Check correctness - dimensions dim(reducedDim(spe, &quot;PCA&quot;)) ## [1] 3511 50 2.4.3 UMAP: Uniform Manifold Approximation and Projection Here we will also run UMAP -using scater’s implementation- on the 50 PCs generated above and retain the top 2 UMAP components to visualise results. ## Set seed set.seed(987) ## Compute UMAP on top 50 PCs spe &lt;- runUMAP(spe, dimred = &quot;PCA&quot;) ## Check correctness - names reducedDimNames(spe) ## [1] &quot;PCA&quot; &quot;UMAP&quot; ## Check correctness - dimensions dim(reducedDim(spe, &quot;UMAP&quot;)) ## [1] 3511 2 ## Update column names for easier plotting colnames(reducedDim(spe, &quot;UMAP&quot;)) &lt;- paste0(&quot;UMAP&quot;, 1:2) 2.4.4 UMAP visualisations We can generate plots either using plotting functions from the ggspavis package or ggplot2 package. Later on clustering, we will add cluster labels to these reduced dimension plots for an off-tissue visualisation. ## Plot top 2 PCA dimensions # plotDimRed(spe, type = &quot;PCA&quot;) ggplot(data = as.data.frame(spe@int_colData@listData$reducedDims$PCA), aes(x = PC1, y = PC2, colour = spe@colData$ground_truth)) + geom_point(size = 0.5) + scale_colour_brewer(type = &quot;qual&quot;) + labs(title = &quot;Reduced dimensions: PCA&quot;, x = &quot;PC1&quot;, y = &quot;PC2&quot;, colour = &quot;Layers&quot;) + theme_classic() ## Plot top 2 UMAP dimensions # plotDimRed(spe, type = &quot;UMAP&quot;) ggplot(data = as.data.frame(spe@int_colData@listData$reducedDims$UMAP), aes(x = UMAP1, y = UMAP2, colour = spe@colData$ground_truth)) + geom_point(size = 0.5) + scale_colour_brewer(type = &quot;qual&quot;) + labs(title = &quot;Reduced dimensions: UMAP&quot;, x = &quot;UMAP1&quot;, y = &quot;UMAP2&quot;, colour = &quot;Layers&quot;) + theme_classic() 2.5 Clustering 2.5.1 Background The clustering of observations into statistically similar groups is a well-established application in both bulk and single-cell RNA-Seq analysis. Clustering is a helpful tool because it structures and orders the data, allowing useful insights to be gained from complex, multivariate datasets and use those insights to classify the observed data or to generate hypotheses. Common clustering methods are applied to ST data based on correlation or statistical distance of gene expression measurements. As we briefly touched above, the dimensionality of ST data means that sample distances in gene expression space tend to be small and not reliable for identifying clusters, so feature selection (gene selection) or dimensionality reduction approaches (i.e., PCA, UMAP) tend to be taken before clustering. Common approaches to clustering gene expression data include k-means, hierarchical and Louvain algorithms, and all have been applied to the clustering of ST data. Some of these methods are implemented in some of the most popular single-cell analysis packages, such as Seurat (Hao et al. 2021) and scran (Lun, McCarthy, and Marioni 2016) and have been used for clustering in a number of ST studies. 2.5.2 Clustering on HVGs Here, we apply graph-based clustering to the top 50 PCs calculated on the set of selected HVGs, using the Walktrap method implemented in scran (Lun, McCarthy, and Marioni 2016). To do so, we assume that (i) each spot is equal to a cell and (ii) we can detect from the gene expression the biologically informative spatial distribution patterns of cell types. ## Set seed set.seed(987) ## Set number of Nearest-Neighbours (NNs) k &lt;- 10 ## Build the k-NN graph g &lt;- buildSNNGraph(spe, k = k, use.dimred = &quot;PCA&quot;) ## Run walktrap clustering g_walk &lt;- igraph::cluster_walktrap(g) ## Get the cluster labels clus &lt;- g_walk$membership ## Check how many table(clus) ## clus ## 1 2 3 4 5 6 ## 350 354 661 895 366 885 ## Store cluster labels in column &#39;label&#39; in colData colLabels(spe) &lt;- factor(clus) 2.5.3 HVGs clustering visualisations We can visualise the clusters in two ways: 1. plotting in spatial coordinates on the tissue map 2. plotting in the UMAP/PCA embeddings. We can use plotting functions either from the ggspavispackage. For reference, we will also display the ground truth (manually annotated) labels available for this dataset. ## Plot in tissue map plotSpots(spe, annotate = &quot;label&quot;, palette = &quot;libd_layer_colors&quot;) ## Plot ground truth in tissue map plotSpots(spe, annotate = &quot;ground_truth&quot;, palette = &quot;libd_layer_colors&quot;) ## Plot clusters in PCA space plotDimRed(spe, type = &quot;PCA&quot;, annotate = &quot;label&quot;, palette = &quot;libd_layer_colors&quot;) ## Plot clusters in UMAP space plotDimRed(spe, type = &quot;UMAP&quot;, annotate = &quot;label&quot;, palette = &quot;libd_layer_colors&quot;) From the visualizations, we can see that the clustering reproduces, up to an extend, the known biological structure of the tissue, but not perfectly. One reason for this could be the fact that each spot may comprise of many different cells whose gene expression profiles are diluted in the overall profile of the spot, thus leading to low-quality clustering. 2.5.4 Spatially-aware clustering In STx data, we can also perform clustering that takes spatial information into account, for example to identify spatially compact or spatially connected clusters. A simple strategy is to perform graph-based clustering on a set of features (columns) that includes both molecular features (gene expression) and spatial features (x-y coordinates). In this case, a crucial tuning parameter is the relative amount of scaling between the two data modalities – if the scaling is chosen poorly, either the molecular or spatial features will dominate the clustering. Depending on data availability, further modalities could also be included. In this section, we will include some examples on this clustering approach. 2.6 Inter-cluster differentially expressed genes (DGEs) 2.6.1 Background Here, we will identify differentially expressed genes bewteen clusters. We will use the findMarkers implementation from the scran (Lun, McCarthy, and Marioni 2016). This implementation uses a binomial test, which tests for genes that differ in the proportion expressed vs. not expressed between clusters. This is a more stringent test than the default t-tests, and tends to select genes that are easier to interpret and validate experimentally. 2.6.2 DGEs identification ## Set gene names as row names ease of plotting rownames(spe) &lt;- rowData(spe)$gene_name ## Test for DGEs markers &lt;- findMarkers(spe, test = &quot;binom&quot;, direction = &quot;up&quot;) ## Check output markers ## List of length 6 ## names(6): 1 2 3 4 5 6 The output from the findMarkers implementation is a list of length equal to the number of clusters. Each element of the list contains the Log-Fold-Change (LogFC) of each gene between one cluster and all others. 2.6.3 DGEs visualisation Here we will plot LogFCs for cluster 1 against all other clusters ## Select cluster 1 genes interesting &lt;- markers[[1]] ## Get the top genes best_set &lt;- interesting[interesting$Top &lt;= 5, ] ## Calculate the effect logFCs &lt;- getMarkerEffects(best_set) ## Plot a heat map pheatmap(logFCs, breaks = seq(-5, 5, length.out = 101)) Below we will plot the log-transformed normalised expression of the top genes for one cluster alongside their expression in the other clusters. ## Select genes top_genes &lt;- head(rownames(interesting)) ## Plot expression plotExpression(spe, x = &quot;label&quot;, features = top_genes) 2.7 Other visualisations 2.8 Putting it all together # # clear workspace from previous chapters # rm(list = ls(all = TRUE)) # # # LOAD DATA # # library(SpatialExperiment) # library(STexampleData) # spe &lt;- Visium_humanDLPFC() # # # QUALITY CONTROL (QC) # # library(scater) # # subset to keep only spots over tissue # spe &lt;- spe[, colData(spe)$in_tissue == 1] # # identify mitochondrial genes # is_mito &lt;- grepl(&quot;(^MT-)|(^mt-)&quot;, rowData(spe)$gene_name) # # calculate per-spot QC metrics # spe &lt;- addPerCellQC(spe, subsets = list(mito = is_mito)) # # select QC thresholds # qc_lib_size &lt;- colData(spe)$sum &lt; 600 # qc_detected &lt;- colData(spe)$detected &lt; 400 # qc_mito &lt;- colData(spe)$subsets_mito_percent &gt; 28 # qc_cell_count &lt;- colData(spe)$cell_count &gt; 10 # # combined set of discarded spots # discard &lt;- qc_lib_size | qc_detected | qc_mito | qc_cell_count # colData(spe)$discard &lt;- discard # # filter low-quality spots # spe &lt;- spe[, !colData(spe)$discard] # # # NORMALIZATION # # library(scran) # # calculate logcounts using library size factors # spe &lt;- logNormCounts(spe) # # # FEATURE SELECTION # # # remove mitochondrial genes # spe &lt;- spe[!is_mito, ] # # fit mean-variance relationship # dec &lt;- modelGeneVar(spe) # # select top HVGs # top_hvgs &lt;- getTopHVGs(dec, prop = 0.1) # # # DIMENSIONALITY REDUCTION # # # compute PCA # set.seed(123) # spe &lt;- runPCA(spe, subset_row = top_hvgs) # # compute UMAP on top 50 PCs # set.seed(123) # spe &lt;- runUMAP(spe, dimred = &quot;PCA&quot;) # # update column names # colnames(reducedDim(spe, &quot;UMAP&quot;)) &lt;- paste0(&quot;UMAP&quot;, 1:2) # # # CLUSTERING # # # graph-based clustering # set.seed(123) # k &lt;- 10 # g &lt;- buildSNNGraph(spe, k = k, use.dimred = &quot;PCA&quot;) # g_walk &lt;- igraph::cluster_walktrap(g) # clus &lt;- g_walk$membership # colLabels(spe) &lt;- factor(clus) # # # MARKER GENES # # test for marker genes # rownames(spe) &lt;- rowData(spe)$gene_name # markers &lt;- findMarkers(spe, test = &quot;binom&quot;, direction = &quot;up&quot;) References "],["practical-session-3.html", "Chapter 3 Practical session 3 3.1 Background 3.2 Data structures preparation", " Chapter 3 Practical session 3 This practical session will demonstrate the application of the most commonly used spatial analysis tools to STx data, and how we work with coordinate data alongside expression data. ## Load packages spdep is a collection of functions to create spatial weights matrix objects from polygon ‘contiguities’, from point patterns by distance and tessellations, for summarizing these objects, and for permitting their use in spatial data analysis like regional aggregation and tests for spatial ‘autocorrelation’. sf (Simple Features for R) is a package that offers support for simple features, a standardized way to encode spatial vector data. GWmodel is a suit of models that fit situations when data are not described well by some global model, but where there are spatial regions where a suitably localised calibration provides a better description. 3.1 Background 3.1.1 Main geocomputatinal data structures There are three main data structures that we need to have ready before we undertake a geocomputational approach to STx data analysis. Namely these are; (1) geometries (point and polygon), (2) neighbours lists and (3) distance matrices. Spatial geometries can be points, lines, polygons and pixels. Polygons consist of a multitude of points connected by lines and can have many forms like circle, hexagon, non-canonical polygon etc. Neighbour lists are special types of lists that contain information about the neighbours of each polygon. The neighbours can be defined either by adjacency or by distance. Distance matrices contain the distances between different points and can be either weighted or un-weighted. The weighted distances are usually objective to each point and its neighbours. Meaning that the closer or farther a neighbour is from the point of focus, the weight of their distance changes according to an applied kernel. Usually in the case of STx data, like the ones generated by the 10X Visium platform, the un-weighted distance between is two points is in pixels and we acquire it from the spaceranger output. 3.1.2 The sf objects Package sf represents simple features as native R objects. All functions and methods in sf that operate on spatial data are prefixed by st_, which refers to spatial type. Simple features are implemented as R native data, using simple data structures (S3 classes, lists, matrix, vector). Typical use involves reading, manipulating and writing of sets of features, with attributes and geometries. As attributes are typically stored in data.frame objects (or the very similar tbl_df), we will also store feature geometries in a data.frame column. Since geometries are not single-valued, they are put in a list-column, a list of length equal to the number of records in the data.frame, with each list element holding the simple feature geometry of that feature. The three classes used to represent simple features are: sf, the table (data.frame) with feature attributes and feature geometries, which contains sfc, the list-column with the geometries for each feature (record), which is composed of sfg, the feature geometry of an individual simple feature. 3.1.2.1 Simple feature geometry types The following seven simple feature types are the most common: type description POINT zero-dimensional geometry containing a single point LINESTRING sequence of points connected by straight, non-self intersecting line pieces; one-dimensional geometry POLYGON geometry with a positive area (two-dimensional); sequence of points form a closed, non-self intersecting ring; the first ring denotes the exterior ring, zero or more subsequent rings denote holes in this exterior ring MULTIPOINT set of points; a MULTIPOINT is simple if no two Points in the MULTIPOINT are equal MULTILINESTRING set of linestrings MULTIPOLYGON set of polygons GEOMETRYCOLLECTION set of geometries of any type except GEOMETRYCOLLECTION Each of the geometry types can also be a (typed) empty set, containing zero coordinates (for POINT the standard is not clear how to represent the empty geometry). Empty geometries can be thought of being the analogue to missing (NA) attributes, NULL values or empty lists. 3.1.2.2 sf: objects with simple features As we usually do not work with geometries of single simple features, but with datasets consisting of sets of features with attributes, the two are put together in sf (simple feature) objects. The following command reads a test dataset called nc from a file that is contained in the sf package: nc &lt;- st_read(system.file(&quot;shape/nc.shp&quot;, package = &quot;sf&quot;)) ## Reading layer `nc&#39; from data source ## `/home/sjcockell/R/x86_64-pc-linux-gnu-library/4.3/sf/shape/nc.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 100 features and 14 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965 ## Geodetic CRS: NAD27 The short report printed gives the file name, the driver (ESRI Shapefile), mentions that there are 100 features (records, represented as rows) and 14 fields (attributes, represented as columns). This object is of class: class(nc) ## [1] &quot;sf&quot; &quot;data.frame&quot; meaning it extends (and “is” a) data.frame, but with a single list-column with geometries, which is held in the column with name: attr(nc, &quot;sf_column&quot;) ## [1] &quot;geometry&quot; If we print the first three features, we see their attribute values and an abridged version of the geometry print(nc[9:15], n = 3) which would give the following output: Figure 3.1: Overview of the sf object. In the output we see: in green a simple feature: a single record, or data.frame row, consisting of attributes and geometry in blue a single simple feature geometry (an object of class sfg) in red a simple feature list-column (an object of class sfc, which is a column in the data.frame) that although geometries are native R objects, they are printed as well-known text It is also possible to create data.frame objects with geometry list-columns that are not of class sf, e.g. by: nc.no_sf &lt;- as.data.frame(nc) class(nc.no_sf) ## [1] &quot;data.frame&quot; However, such objects: no longer register which column is the geometry list-column no longer have a plot method, and lack all of the other dedicated methods for class sf 3.1.2.3 sfc: simple feature geometry list-column The column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by using standard data.frame notation like nc$geom or nc[[15]], but the more general way uses st_geometry: (nc_geom &lt;- st_geometry(nc)) ## Geometry set for 100 features ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965 ## Geodetic CRS: NAD27 ## First 5 geometries: ## MULTIPOLYGON (((-81.47276 36.23436, -81.54084 3... ## MULTIPOLYGON (((-81.23989 36.36536, -81.24069 3... ## MULTIPOLYGON (((-80.45634 36.24256, -80.47639 3... ## MULTIPOLYGON (((-76.00897 36.3196, -76.01735 36... ## MULTIPOLYGON (((-77.21767 36.24098, -77.23461 3... Geometries are printed in abbreviated form, but we can view a complete geometry by selecting it, e.g. the first one by: nc_geom[[1]] ## MULTIPOLYGON (((-81.47276 36.23436, -81.54084 36.27251, -81.56198 36.27359, -81.63306 36.34069, -81.74107 36.39178, -81.69828 36.47178, -81.7028 36.51934, -81.67 36.58965, -81.3453 36.57286, -81.34754 36.53791, -81.32478 36.51368, -81.31332 36.4807, -81.26624 36.43721, -81.26284 36.40504, -81.24069 36.37942, -81.23989 36.36536, -81.26424 36.35241, -81.32899 36.3635, -81.36137 36.35316, -81.36569 36.33905, -81.35413 36.29972, -81.36745 36.2787, -81.40639 36.28505, -81.41233 36.26729, -81.43104 36.26072, -81.45289 36.23959, -81.47276 36.23436))) The way this is printed is called well-known text, and is part of the standards. The word MULTIPOLYGON is followed by three parentheses, because it can consist of multiple polygons, in the form of MULTIPOLYGON(POL1,POL2), where POL1 might consist of an exterior ring and zero or more interior rings, as of (EXT1,HOLE1,HOLE2). Sets of coordinates are held together with parentheses, so we get ((crds_ext)(crds_hole1)(crds_hole2)) where crds_ is a comma-separated set of coordinates of a ring. This leads to the case above, where MULTIPOLYGON(((crds_ext))) refers to the exterior ring (1), without holes (2), of the first polygon (3) - hence three parentheses. We can see there is a single polygon with no rings: par(mar = c(0,0,1,0)) plot(nc[1], reset = FALSE) # reset = FALSE: we want to add to a plot with a legend plot(nc[1,1], col = &#39;grey&#39;, add = TRUE) Following the MULTIPOLYGON data structure, in R we have a list of lists of lists of matrices. For instance, we get the first 3 coordinate pairs of the second exterior ring (first ring is always exterior) for the geometry of feature 4 by: nc_geom[[4]][[2]][[1]][1:3,] ## [,1] [,2] ## [1,] -76.02717 36.55672 ## [2,] -75.99866 36.55665 ## [3,] -75.91192 36.54253 Geometry columns have their own class, class(nc_geom) ## [1] &quot;sfc_MULTIPOLYGON&quot; &quot;sfc&quot; 3.1.2.4 sfg: simple feature geometry Simple feature geometry (sfg) objects carry the geometry for a single feature, e.g. a point, linestring or polygon. Simple feature geometries are implemented as R native data, using the following rules a single POINT is a numeric vector a set of points, e.g. in a LINESTRING or ring of a POLYGON is a matrix, each row containing a point any other set is a list The below figure illustrates the different types of geometries: Geometries can also be empty, as in (x &lt;- st_geometrycollection()) ## GEOMETRYCOLLECTION EMPTY length(x) ## [1] 0 The above are taken from the very well written, well-descriptive and thorough sf package vignette. 3.2 Data structures preparation For this practical we will be using a human steatotic kidney dataset from the Liver Atlas (Guilliams et al. 2022). Specifically we will use the JBO019 sample. 3.2.1 Load new dataset First we generate the SpatialFeaturesExperiment object which is an extension of the SpatialExperiment (SPE) object that we used in the 2nd practical session. The difference is that the SFE object has incorporated the sf object structure and thus can accommodate the use of geocomputational tools. sampleDir &lt;- &quot;./data/spaceranger_outs/Human_Liver_Steatotic/JBO019_Results&quot; sampleNames &lt;- &quot;JBO019&quot; sfe &lt;- read10xVisiumSFE(samples = sampleDir, sample_id = sampleNames, type = &quot;sparse&quot;, data = &quot;filtered&quot;, images = &quot;lowres&quot;, style = &quot;W&quot;, zero.policy = TRUE) ground_truth &lt;- read_table(&quot;./data/spotzonationGroup.txt&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## Barcode = col_character(), ## sample_id = col_character(), ## annotation = col_character() ## ) is_mito &lt;- grepl(&quot;(^MT-)|(^mt-)&quot;, rowData(sfe)$symbol) sfe &lt;- addPerLocQC(sfe, gTruth = ground_truth, assay = &quot;counts&quot;, 2, subsets = list(mito = is_mito)) sfe &lt;- addGeometries(sfe, samples = sampleDir, sample_id = sampleNames, res = &quot;fullres&quot;) ggplot() + geom_sf(aes(geometry = colGeometries(sfe)$spotHex$geometry, fill = colData(sfe)$annotation)) + theme_void() + theme(legend.position = &quot;right&quot;) + labs(fill = &quot;Annotation&quot;) sfe &lt;- addPerGeneQC(sfe, assay = &quot;counts&quot;, version = 92) sfe &lt;- get.spatialNeighGraphs(sfe, sampleNames, type = &quot;knearneigh&quot;, style = &quot;W&quot;, distMod = &quot;raw&quot;, k = 6) colData(sfe) ## DataFrame with 1185 rows and 15 columns ## Barcode sample_id in_tissue array_row array_col ## &lt;character&gt; &lt;character&gt; &lt;logical&gt; &lt;integer&gt; &lt;integer&gt; ## AAACAAGTATCTCCCA-1 AAACAAGTATCTCCCA-1 JBO019 TRUE 50 102 ## AAACATTTCCCGGATT-1 AAACATTTCCCGGATT-1 JBO019 TRUE 61 97 ## AAACCCGAACGAAATC-1 AAACCCGAACGAAATC-1 JBO019 TRUE 45 115 ## AAACGAGACGGTTGAT-1 AAACGAGACGGTTGAT-1 JBO019 TRUE 35 79 ## AAACTAACGTGGCGAC-1 AAACTAACGTGGCGAC-1 JBO019 TRUE 8 110 ## ... ... ... ... ... ... ## TTGTAATCCGTACTCG-1 TTGTAATCCGTACTCG-1 JBO019 TRUE 35 55 ## TTGTGAACCTAATCCG-1 TTGTGAACCTAATCCG-1 JBO019 TRUE 56 90 ## TTGTGCAGCCACGTCA-1 TTGTGCAGCCACGTCA-1 JBO019 TRUE 60 74 ## TTGTGTTTCCCGAAAG-1 TTGTGTTTCCCGAAAG-1 JBO019 TRUE 51 59 ## TTGTTGTGTGTCAAGA-1 TTGTTGTGTGTCAAGA-1 JBO019 TRUE 31 77 ## Capt_area annotation index sparsity sum ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; ## AAACAAGTATCTCCCA-1 1 NA spot_1 0.910410 13443 ## AAACATTTCCCGGATT-1 1 NA spot_2 0.967805 2648 ## AAACCCGAACGAAATC-1 1 Mid spot_3 0.864958 27733 ## AAACGAGACGGTTGAT-1 1 Central spot_4 0.835818 32973 ## AAACTAACGTGGCGAC-1 1 NA spot_5 0.995418 400 ## ... ... ... ... ... ... ## TTGTAATCCGTACTCG-1 1 NA spot_1181 0.933716 7612 ## TTGTGAACCTAATCCG-1 1 NA spot_1182 0.955831 4299 ## TTGTGCAGCCACGTCA-1 1 NA spot_1183 0.978252 1452 ## TTGTGTTTCCCGAAAG-1 1 NA spot_1184 0.956778 3831 ## TTGTTGTGTGTCAAGA-1 1 Mid spot_1185 0.852160 27755 ## detected subsets_mito_sum subsets_mito_detected ## &lt;integer&gt; &lt;numeric&gt; &lt;integer&gt; ## AAACAAGTATCTCCCA-1 2933 1021 12 ## AAACATTTCCCGGATT-1 1054 285 12 ## AAACCCGAACGAAATC-1 4421 2087 12 ## AAACGAGACGGTTGAT-1 5375 821 12 ## AAACTAACGTGGCGAC-1 150 182 11 ## ... ... ... ... ## TTGTAATCCGTACTCG-1 2170 733 11 ## TTGTGAACCTAATCCG-1 1446 515 12 ## TTGTGCAGCCACGTCA-1 712 54 10 ## TTGTGTTTCCCGAAAG-1 1415 422 11 ## TTGTTGTGTGTCAAGA-1 4840 906 12 ## subsets_mito_percent total ## &lt;numeric&gt; &lt;numeric&gt; ## AAACAAGTATCTCCCA-1 7.59503 13443 ## AAACATTTCCCGGATT-1 10.76284 2648 ## AAACCCGAACGAAATC-1 7.52533 27733 ## AAACGAGACGGTTGAT-1 2.48992 32973 ## AAACTAACGTGGCGAC-1 45.50000 400 ## ... ... ... ## TTGTAATCCGTACTCG-1 9.62953 7612 ## TTGTGAACCTAATCCG-1 11.97953 4299 ## TTGTGCAGCCACGTCA-1 3.71901 1452 ## TTGTGTTTCCCGAAAG-1 11.01540 3831 ## TTGTTGTGTGTCAAGA-1 3.26428 27755 rowData(sfe) ## DataFrame with 32738 rows and 21 columns ## id gene_name biotype ## &lt;character&gt; &lt;character&gt; &lt;character&gt; ## ENSG00000243485 ENSG00000243485 MIR1302-2HG lincRNA ## ENSG00000237613 ENSG00000237613 FAM138A lincRNA ## ENSG00000186092 ENSG00000186092 OR4F5 protein_coding ## ENSG00000238009 ENSG00000238009 AL627309.1 lincRNA ## ENSG00000239945 ENSG00000239945 AL627309.3 lincRNA ## ... ... ... ... ## ENSG00000215635 ENSG00000215635 NA NA ## ENSG00000268590 ENSG00000268590 NA NA ## ENSG00000251180 ENSG00000251180 NA NA ## ENSG00000215616 ENSG00000215616 NA NA ## ENSG00000215611 ENSG00000215611 NA NA ## description symbol mean detected ## &lt;character&gt; &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 MIR1302-2 host gene MIR1302-10 0.00000000 0.000000 ## ENSG00000237613 family with sequence.. FAM138A 0.00000000 0.000000 ## ENSG00000186092 olfactory receptor f.. OR4F5 0.00000000 0.000000 ## ENSG00000238009 RP11-34P13.7 0.00590717 0.590717 ## ENSG00000239945 RP11-34P13.8 0.00000000 0.000000 ## ... ... ... ... ... ## ENSG00000215635 NA AC145205.1 0 0 ## ENSG00000268590 NA BAGE5 0 0 ## ENSG00000251180 NA CU459201.1 0 0 ## ENSG00000215616 NA AC002321.2 0 0 ## ENSG00000215611 NA AC002321.1 0 0 ## total JBO019.sparsity JBO019.total JBO019.nLocations ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;integer&gt; ## ENSG00000243485 0 1.000000 0 0 ## ENSG00000237613 0 1.000000 0 0 ## ENSG00000186092 0 1.000000 0 0 ## ENSG00000238009 7 0.994093 7 7 ## ENSG00000239945 0 1.000000 0 0 ## ... ... ... ... ... ## ENSG00000215635 0 1 0 0 ## ENSG00000268590 0 1 0 0 ## ENSG00000251180 0 1 0 0 ## ENSG00000215616 0 1 0 0 ## ENSG00000215611 0 1 0 0 ## JBO019.s_min JBO019.max JBO019.s_mean JBO019.s_median ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 Inf 0 NaN NA ## ENSG00000237613 Inf 0 NaN NA ## ENSG00000186092 Inf 0 NaN NA ## ENSG00000238009 1 1 1 1 ## ENSG00000239945 Inf 0 NaN NA ## ... ... ... ... ... ## ENSG00000215635 Inf 0 NaN NA ## ENSG00000268590 Inf 0 NaN NA ## ENSG00000251180 Inf 0 NaN NA ## ENSG00000215616 Inf 0 NaN NA ## ENSG00000215611 Inf 0 NaN NA ## JBO019.s_SD JBO019.p_mean JBO019.p_median JBO019.p_SD ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 NA 0.00000000 0 0.0000000 ## ENSG00000237613 NA 0.00000000 0 0.0000000 ## ENSG00000186092 NA 0.00000000 0 0.0000000 ## ENSG00000238009 0 0.00590717 0 0.0766631 ## ENSG00000239945 NA 0.00000000 0 0.0000000 ## ... ... ... ... ... ## ENSG00000215635 NA 0 0 0 ## ENSG00000268590 NA 0 0 0 ## ENSG00000251180 NA 0 0 0 ## ENSG00000215616 NA 0 0 0 ## ENSG00000215611 NA 0 0 0 ## JBO019.s_CV JBO019.p_CV ## &lt;numeric&gt; &lt;numeric&gt; ## ENSG00000243485 NA NaN ## ENSG00000237613 NA NaN ## ENSG00000186092 NA NaN ## ENSG00000238009 0 1297.8 ## ENSG00000239945 NA NaN ## ... ... ... ## ENSG00000215635 NA NaN ## ENSG00000268590 NA NaN ## ENSG00000251180 NA NaN ## ENSG00000215616 NA NaN ## ENSG00000215611 NA NaN colGeometries(sfe) ## List of length 3 ## names(3): spotPoly spotCntd spotHex colGraphs(sfe) ## $col ## Characteristics of weights list object: ## Neighbour list object: ## Number of regions: 1185 ## Number of nonzero links: 7110 ## Percentage nonzero weights: 0.5063291 ## Average number of links: 6 ## Non-symmetric neighbours list ## ## Weights style: W ## Weights constants summary: ## n nn S0 S1 S2 ## W 1185 1404225 1185 385.3889 4770 # &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;possible break point to continue on Pract 4&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; # # Above we load the data and calculate some statistics, generate some # neighbour graphs and we can explore the data structures. Below we # apply the QC. # There is a catch in the above. The get.spatialNeighGraphs is going to be used # here to showcase the neighbour graphs but actually it is better to be called # after we remove unwanted locations through QC application # Ensembl version 92 does not match the dataset. Need to find out which # ensembl version they used with SpaceRanger. Otherwise some genes will not have # proper annotation. # &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;possible break point to continue on Pract 4&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; # ## Select library size threshold qc_lib_size &lt;- colData(sfe)$sum &lt; 700 ## Check how many spots are filtered out table(qc_lib_size) ## qc_lib_size ## FALSE TRUE ## 1171 14 ## Add threshold in colData colData(sfe)$qc_lib_size &lt;- qc_lib_size ## Select expressed genes threshold qc_detected &lt;- colData(sfe)$detected &lt; 500 ## Check how many spots are filtered out table(qc_detected) ## qc_detected ## FALSE TRUE ## 1168 17 ## Add threshold in colData colData(sfe)$qc_detected &lt;- qc_detected ## Select expressed genes threshold qc_mito &lt;- colData(sfe)$subsets_mito_percent &gt; 25 ## Check how many spots are filtered out table(qc_mito) ## qc_mito ## FALSE TRUE ## 1184 1 ## Add threshold in colData colData(sfe)$qc_mito &lt;- qc_mito ## Check the number of discarded spots for each metric apply(cbind(qc_lib_size, qc_detected, qc_mito), 2, sum) ## qc_lib_size qc_detected qc_mito ## 14 17 1 ## Combine together the set of discarded spots discard &lt;- qc_lib_size | qc_detected | qc_mito ## Store the set in the object colData(sfe)$discard &lt;- discard ## Check the spatial pattern of combined set of discarded spots plotQC(sfe, type = &quot;spots&quot;, discard = &quot;discard&quot;) ## remove combined set of low-quality spots sfe &lt;- sfe[, !colData(sfe)$discard] ## Calculate library size factors sfe &lt;- computeLibraryFactors(sfe) ## Have a look at the size factors summary(sizeFactors(sfe)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.06573 0.36598 0.95403 1.00000 1.55396 2.78681 # calculate logcounts using library size factors sfe &lt;- logNormCounts(sfe) # FEATURE SELECTION # remove mitochondrial genes sfe &lt;- sfe[!is_mito, ] # fit mean-variance relationship dec &lt;- modelGeneVar(sfe) # select top HVGs top_hvgs &lt;- getTopHVGs(dec, prop = 0.1) 3.2.1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1 ## Load counts table inputD &lt;- readRDS(file = &quot;./data/hsLivSteat_JBO019_inputD.rds&quot;) inputD[1:5, 1:3] ## AAACAAGTATCTCCCA.1 AAACATTTCCCGGATT.1 AAACCCGAACGAAATC.1 ## ENSG00000243485 0 0 0 ## ENSG00000237613 0 0 0 ## ENSG00000186092 0 0 0 ## ENSG00000238009 0 0 0 ## ENSG00000239945 0 0 0 Then we load the spot metadata. The imported table has the below columns: Barcode: the spot barcode (note that we substituted the “-” with a “.” to match the column names in the inputD because it is not good practise to have “-” in column names in R). Section: whether the spot is on- or off- tissue (on-tissue = 1, off-tissue = 0). Spot_Y/ Spot_X: X and Y spot location on the capture area array. Image_Y/ Image_X: X and Y spot coordinates in the full resolution image. pixel_x/ pixel_y: X and Y spot coordinates in the low resolution image. ## Load spot metadata inputMD &lt;- readRDS(file = &quot;./data/hsLivSteat_JBO019_inputMD.rds&quot;) head(inputMD) ## Barcode Section Spot_Y Spot_X Image_Y Image_X pixel_x pixel_y ## 1 ACGCCTGACACGCGCT.1 0 0 0 16961 2500 68.85156 467.1165 ## 2 TACCGATCCAACACTT.1 0 1 1 16847 2696 74.24952 463.9769 ## 3 ATTAAAGCGGACGAGC.1 0 0 2 16735 2499 68.82401 460.8923 ## 4 GATAAGGGACGATTAG.1 0 1 3 16621 2695 74.22198 457.7527 ## 5 GTGCAAATCACCAATA.1 0 0 4 16509 2497 68.76893 454.6681 ## 6 TGTTGGCTGGCGGAAG.1 0 1 5 16395 2693 74.16690 451.5285 3.2.2 Create point geometries First we want to extract the pixel coordinates from the inputMD data frame and then we will generate the point geometries (centroids) from all spots of the 10X Visium capture area. This helps to tessellate space better in the next step. ## Extract coordinates spot_position &lt;- inputMD %&gt;% select(c(&quot;Barcode&quot;, &quot;pixel_x&quot;, &quot;pixel_y&quot;, &quot;Section&quot;)) head(spot_position, 5) ## Barcode pixel_x pixel_y Section ## 1 ACGCCTGACACGCGCT.1 68.85156 467.1165 0 ## 2 TACCGATCCAACACTT.1 74.24952 463.9769 0 ## 3 ATTAAAGCGGACGAGC.1 68.82401 460.8923 0 ## 4 GATAAGGGACGATTAG.1 74.22198 457.7527 0 ## 5 GTGCAAATCACCAATA.1 68.76893 454.6681 0 ## Convert spots to centroids centroids &lt;- spot_position %&gt;% st_as_sf(coords = c(&quot;pixel_x&quot;, &quot;pixel_y&quot;), remove = FALSE) head(centroids, 5) ## Simple feature collection with 5 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 68.76893 ymin: 454.6681 xmax: 74.24952 ymax: 467.1165 ## CRS: NA ## Barcode pixel_x pixel_y Section geometry ## 1 ACGCCTGACACGCGCT.1 68.85156 467.1165 0 POINT (68.85156 467.1165) ## 2 TACCGATCCAACACTT.1 74.24952 463.9769 0 POINT (74.24952 463.9769) ## 3 ATTAAAGCGGACGAGC.1 68.82401 460.8923 0 POINT (68.82401 460.8923) ## 4 GATAAGGGACGATTAG.1 74.22198 457.7527 0 POINT (74.22198 457.7527) ## 5 GTGCAAATCACCAATA.1 68.76893 454.6681 0 POINT (68.76893 454.6681) 3.2.3 Tesselate space Here we will take the steps towards tessellating space. This tessellation, brakes the area that surrounds the spots and as a result we can use it to find neighbours by adjacency later on. We need to always keep in mind that although tessellation makes the spots have common borders, the 10X Visium spots have a distance between them that is approximately 50μm. First, we combine the points we calculated earlier into a multipoint geometry. Second, we tessellate space around the points using the Voronoi tessellation. Third, we can cut the tessellation around the edges because tessellation extends to infinity. ## Combine the points into a multipoint geometry: cntd_union &lt;- st_union(centroids) head(cntd_union) ## Geometry set for 1 feature ## Geometry type: MULTIPOINT ## Dimension: XY ## Bounding box: xmin: 66.45552 ymin: 69.04434 xmax: 486.1195 ymax: 467.1165 ## CRS: NA ## MULTIPOINT ((66.45552 74.69017), (66.5106 80.91... ## Use the union of points to generate a voronoi object voronoi &lt;- st_voronoi(cntd_union, bOnlyEdges = TRUE) head(voronoi) ## Geometry set for 1 feature ## Geometry type: MULTILINESTRING ## Dimension: XY ## Bounding box: xmin: -353.2085 ymin: -350.6197 xmax: 905.7835 ymax: 886.7805 ## CRS: NA ## MULTILINESTRING ((68.32756 84.03226, 70.14669 8... ## Create an enveloped voronoi tessellation around the tissue voronoi_env &lt;- st_intersection(st_cast(voronoi), st_convex_hull(cntd_union)) head(voronoi_env) ## Geometry set for 1 feature ## Geometry type: MULTILINESTRING ## Dimension: XY ## Bounding box: xmin: 66.47385 ymin: 69.06262 xmax: 486.1006 ymax: 467.0982 ## CRS: NA ## MULTILINESTRING ((68.32756 84.03226, 70.14669 8... ## Plot tessellation as is ggplot(data = voronoi) + geom_sf() + labs(title = &quot;Tessellation&quot;) + theme_void() ## Plot enveloped tessellation ggplot(data = voronoi_env) + geom_sf() + labs(title = &quot;Tessellation cut to capture area&quot;) + theme_void() 3.2.4 Polygonise the tessellation Here we will extract polygons from the tessellation object only for the spots that are on-tissue. Meaning, they have a value of 1 in the Section column. ## Generate the POLYGONS from the MULTILINESTRING polygons &lt;- st_polygonize(voronoi_env) %&gt;% # polygonise the tessellation st_cast() %&gt;% # convert GEOMETRYCOLLECTION to multiple POLYGONS st_sf() %&gt;% # convert sfc object to sf for st_join afterwards st_join(., centroids[centroids$Section == 1,], join = st_contains, left = FALSE) %&gt;% dplyr::rename(geom_pol = geometry) %&gt;% # Join the centroids with the POLYGONS mutate(Barcode_rn = Barcode) %&gt;% # duplicate the barcode column column_to_rownames(&quot;Barcode_rn&quot;) %&gt;% # move duplicate column to row names st_sf() # convert back to sf (mutate makes it a df) head(polygons) ## Simple feature collection with 6 features and 4 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 106.5067 ymin: 121.1432 xmax: 201.425 ymax: 304.4226 ## CRS: NA ## Barcode pixel_x pixel_y Section ## AAACTAACGTGGCGAC.1 AAACTAACGTGGCGAC.1 110.1074 124.2633 1 ## GACTAAGATCATGCAC.1 GACTAAGATCATGCAC.1 192.4814 301.2944 1 ## ATCGACTCTTTCCGTT.1 ATCGACTCTTTCCGTT.1 192.3437 276.3701 1 ## TGGTTCGTAGCAAAGG.1 TGGTTCGTAGCAAAGG.1 192.4539 295.0702 1 ## GCTCTAAACCCTGACG.1 GCTCTAAACCCTGACG.1 197.8243 285.6789 1 ## TCAAACAACCGCGTCG.1 TCAAACAACCGCGTCG.1 197.7692 279.4547 1 ## geom_pol ## AAACTAACGTGGCGAC.1 POLYGON ((108.2826 121.1592... ## GACTAAGATCATGCAC.1 POLYGON ((188.8807 301.3139... ## ATCGACTCTTTCCGTT.1 POLYGON ((190.496 273.2742,... ## TGGTTCGTAGCAAAGG.1 POLYGON ((190.6062 291.9742... ## GCTCTAAACCCTGACG.1 POLYGON ((195.9765 282.5829... ## TCAAACAACCGCGTCG.1 POLYGON ((194.1607 279.4881... As you may have observed we joined the polygons object with the centroids object so that we can add the rest of the information like Barcode, pixel_x, and pixel_y. If we plot it: ## Plot on tissue polygons ggplot(data = polygons) + geom_sf(aes(geometry = geom_pol)) + theme_void() Because there are times that we will need the polygons and times that we will need their centroids we can add both geometries in the polygons object. ## Update the polygon object to keep the centroid geometries as well polygons &lt;- polygons %&gt;% # rename polygons geom column left_join(as.data.frame(centroids)) %&gt;% # left joint pols and cntds dplyr::rename(geom_cntd = geometry) %&gt;% # rename centroids geom column st_sf(sf_column_name = &quot;geom_pol&quot;) # set polygons geom column to be the default (one must be) head(polygons) ## Simple feature collection with 6 features and 4 fields ## Active geometry column: geom_pol ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 106.5067 ymin: 121.1432 xmax: 201.425 ymax: 304.4226 ## CRS: NA ## Barcode pixel_x pixel_y Section geom_pol ## 1 AAACTAACGTGGCGAC.1 110.1074 124.2633 1 POLYGON ((108.2826 121.1592... ## 2 GACTAAGATCATGCAC.1 192.4814 301.2944 1 POLYGON ((188.8807 301.3139... ## 3 ATCGACTCTTTCCGTT.1 192.3437 276.3701 1 POLYGON ((190.496 273.2742,... ## 4 TGGTTCGTAGCAAAGG.1 192.4539 295.0702 1 POLYGON ((190.6062 291.9742... ## 5 GCTCTAAACCCTGACG.1 197.8243 285.6789 1 POLYGON ((195.9765 282.5829... ## 6 TCAAACAACCGCGTCG.1 197.7692 279.4547 1 POLYGON ((194.1607 279.4881... ## geom_cntd ## 1 POINT (110.1074 124.2633) ## 2 POINT (192.4814 301.2944) ## 3 POINT (192.3437 276.3701) ## 4 POINT (192.4539 295.0702) ## 5 POINT (197.8243 285.6789) ## 6 POINT (197.7692 279.4547) As we can see here we have two geometry columns; one named geom_pol and one named geom_cntd. As a result we need to have one of these two as the active geometry column for the polygons object of class sf. We can see at the top of the printed output that the active geometry column is geom_pol. In general we can switch between geometry columns using: st_geometry(sf_object) &lt;- \"geom_column_to_change_to\" 3.2.5 Identify neighbours 3.2.5.1 By contiguity We can contiguity-based neighbours for each spot using the poly2nb function from spdep. The function is using heuristics to identify polygons sharing boundary points as neighbours. It also has a snap = argument, to allow the shared boundary points to be a short distance from one another. Here we select snap = 0 because the tessellation generated polygons with shared borders. Finally, the queen = argument is set to TRUE. This means that the function will look for a chess queen-style of contiguities. ## Get contiguity neighbours nb_adjc &lt;- poly2nb(pl = polygons, snap = 0, queen = TRUE) length(nb_adjc) ## [1] 1184 head(nb_adjc) ## [[1]] ## [1] 0 ## ## [[2]] ## [1] 4 7 11 ## ## [[3]] ## [1] 6 10 ## ## [[4]] ## [1] 2 7 8 ## ## [[5]] ## [1] 6 8 12 15 ## ## [[6]] ## [1] 3 5 10 12 13 nb_adjc_n &lt;- card(nb_adjc) ggplot() + geom_histogram(aes(x = nb_adjc_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = nb_adjc_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 6)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of Neighbours&quot;) + theme_classic() ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_adjc, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() As you can see, the neighbours object is a list of length equal to the number of spots we have in the dataset. Each element of the list represents a spot and the numbers stored inside the indexes of the neighbouring spots and the spots have a different numbers of neighbours. The connectivity histogram visualises the distribution of the number of neighbours in the data. 3.2.5.2 By graph Once representative points are available, the criteria for neighbourhood can be extended from just contiguity to include graph measures, distance thresholds, and 𝑘-nearest neighbours. The most direct graph representation of neighbours is to make a Delaunay triangulation of the points, which extends outwards to the convex hull of the points. Note that graph-based representations construct the interpoint relationships based on Euclidean distance. Because it joins distant points around the convex hull, it may be worthwhile to thin the triangulation as a Sphere of Influence (SOI) graph, removing links that are relatively long. Points are SOI neighbours if circles centred on the points, of radius equal to the points’ nearest neighbour distances, intersect in two places (Avis and Horton 1985). ## Set centroids as default geometry st_geometry(polygons) &lt;- &quot;geom_cntd&quot; ## Get the neighbour names nb_names &lt;- polygons$Barcode ## By Delaunay triangulation nb_tri &lt;- tri2nb(polygons$geom_cntd, row.names = nb_names) length(nb_tri) ## [1] 1184 head(nb_tri) ## [[1]] ## [1] 2 3 4 52 53 61 71 78 79 80 81 82 83 84 85 86 88 91 103 ## [20] 155 ## ## [[2]] ## [1] 1 4 7 9 11 ## ## [[3]] ## [1] 1 4 5 6 10 35 61 ## ## [[4]] ## [1] 1 2 3 5 7 8 ## ## [[5]] ## [1] 3 4 6 8 12 15 ## ## [[6]] ## [1] 3 5 10 12 13 nb_tri_n &lt;- card(nb_tri) ggplot() + geom_histogram(aes(x = nb_tri_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = nb_tri_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of Neighbours&quot;) + theme_classic() ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_tri, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() ## Get neighbours by SOI nb_soi &lt;- graph2nb(soi.graph(nb_tri, polygons$geom_cntd), row.names = nb_names) length(nb_soi) ## [1] 1184 head(nb_soi) ## [[1]] ## [1] 52 53 78 79 ## ## [[2]] ## [1] 4 7 9 11 ## ## [[3]] ## [1] 5 6 10 ## ## [[4]] ## [1] 2 5 7 8 ## ## [[5]] ## [1] 3 4 6 8 12 15 ## ## [[6]] ## [1] 3 5 10 12 13 nb_soi_n &lt;- card(nb_soi) ggplot() + geom_histogram(aes(x = nb_soi_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = nb_soi_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of Neighbours&quot;) + theme_classic() ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_soi, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() ## Get neighbours by Gabriel graph nb_gbn &lt;- graph2nb(gabrielneigh(polygons$geom_cntd), row.names = nb_names) length(nb_gbn) ## [1] 1184 head(nb_gbn) ## [[1]] ## [1] 53 ## ## [[2]] ## [1] 4 7 11 ## ## [[3]] ## [1] 6 10 ## ## [[4]] ## [1] 7 8 ## ## [[5]] ## [1] 6 8 12 15 ## ## [[6]] ## [1] 10 12 13 nb_gbn_n &lt;- card(nb_gbn) ggplot() + geom_histogram(aes(x = nb_gbn_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = nb_gbn_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 4)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of Neighbours&quot;) + theme_classic() ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_gbn, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() ## Get Relative graph neighbours nb_rn &lt;- graph2nb(relativeneigh(polygons$geom_cntd), row.names = nb_names) length(nb_rn) ## [1] 1184 head(nb_rn) ## [[1]] ## [1] 53 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 6 ## ## [[4]] ## [1] 7 ## ## [[5]] ## [1] 6 8 15 ## ## [[6]] ## [1] 10 nb_rn_n &lt;- card(nb_rn) ggplot() + geom_histogram(aes(x = nb_rn_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = nb_rn_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of Neighbours&quot;) + theme_classic() ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_rn, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() Delaunay triangulation neighbours and SOI neighbours are symmetric by design – if 𝑖 is a neighbour of 𝑗, then 𝑗 is a neighbour of 𝑖. The Gabriel graph is also a subgraph of the Delaunay triangulation, retaining a different set of neighbours (Matula and Sokal 1980). It does not, however, guarantee symmetry; the same applies to Relative graph neighbours (Toussaint 1980). 3.2.5.3 By distance An alternative method is to choose the 𝑘 nearest points as neighbours – this adapts across the study area, taking account of differences in the densities of areal entities. Naturally, in the overwhelming majority of cases, it leads to asymmetric neighbours, but will ensure that all areas have 𝑘 neighbours. ## Set centroids as default geometry st_geometry(polygons) &lt;- &quot;geom_cntd&quot; ## Get distance-based neighbours nb_knn &lt;- knn2nb(knearneigh(polygons, k = 6), row.names = nb_names) length(nb_knn) ## [1] 1184 head(nb_knn) ## [[1]] ## [1] 52 53 74 76 77 78 ## ## [[2]] ## [1] 4 7 8 9 11 19 ## ## [[3]] ## [1] 5 6 10 12 13 18 ## ## [[4]] ## [1] 2 5 7 8 11 14 ## ## [[5]] ## [1] 6 8 12 13 14 15 ## ## [[6]] ## [1] 3 5 10 12 13 18 ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_knn, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() As you can see, this neighbours object is also a list of length equal to the number of spots we have in the dataset with the same content as the one earlier. Also, in this list all spots have the same number of neighbours since we selected k = 6 which means we have the 6 nearest by distance spots. Another interesting fact here is that spots that are not adjacent to each other now might be neighbours. Another way to find neighbours by distance is to first generate a graph for k = 1. This way we can find the shortest and the longest distance needed for a spot to acquire one neighbour. Then, we can use another function called dnearneigh which is used to find neighbours with an interpoint distance, with arguments d1 and d2 setting the lower and upper distance bounds. There as a lower bound we can provide zero or the shortest distance a neighbour is found in our dataset and as an upper bound we can provide a value that is a function of the largest distance a neighbour is found in our dataset. ## Get distance-based neighbours for k = 1 nb_1nn &lt;- knn2nb(knearneigh(polygons, k = 1), row.names = nb_names) dsts &lt;- unlist(nbdists(nb_1nn, polygons$geom_cntd)) summary(dsts) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 6.224 6.224 6.224 6.320 6.224 114.870 max_1nn &lt;- max(dsts) min_1nn &lt;- min(dsts) As you can see, because the 10X Visium spots are equidistant, the majority of the distances is around 6 pixels. Additionally, the maximum distance is almost 20 times the minimum. This is due to the one spot we keep having on the left of our tissue area. As a result in our dataset we will use as upper bound a value that is a function of the minimum distance instead of the maximum. Let’s have a look at how the dataset looks with the maximum as upper boundary nb_1nna &lt;- dnearneigh(polygons$geom_cntd, d1 = 0, d2 = 1*max_1nn, row.names = nb_names) str(nb_1nna[1:5]) ## List of 5 ## $ : int 53 ## $ : int [1:334] 3 4 5 6 7 8 9 10 11 12 ... ## $ : int [1:387] 2 4 5 6 7 8 9 10 11 12 ... ## $ : int [1:347] 2 3 5 6 7 8 9 10 11 12 ... ## $ : int [1:392] 2 3 4 6 7 8 9 10 11 12 ... nb_1nna_n &lt;- card(nb_1nna) ggplot() + geom_histogram(aes(x = nb_1nna_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = nb_1nna_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + xlab(&quot;Number of Neighbours&quot;) + theme_classic() As you can see, the number of neighbours each spot acquires because we use the maximum distance as the upper bound is massive and as a result it will not plot correctly. nb_1nnb &lt;- dnearneigh(polygons$geom_cntd, d1 = 0, d2 = 1*min_1nn, row.names = nb_names) nb_1nnc &lt;- dnearneigh(polygons$geom_cntd, d1 = 0, d2 = 1.5*min_1nn, row.names = nb_names) nb_1nnd &lt;- dnearneigh(polygons$geom_cntd, d1 = 0, d2 = 1.75*min_1nn, row.names = nb_names) ps &lt;- grep(&quot;nn[b,c,d]&quot;, names(.GlobalEnv), value = TRUE) for (p in ps) { q &lt;- get(p) (ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(q, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.1) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 0.25) + labs(title = p) + theme_void()) %&gt;% print() } for(p in ps) { q &lt;- get(p) q_n &lt;- card(q) (ggplot() + geom_histogram(aes(x = q_n, y = after_stat(density)), colour = &quot;black&quot;, fill = &quot;grey&quot;) + geom_density(aes(x = q_n), alpha = 0.5, adjust = 0.5, fill = &quot;#A0CBE8&quot;, colour = &quot;#4E79A7&quot;) + scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + labs(title = p, x = &quot;Number of Neighbours&quot;) + theme_classic()) %&gt;% print() } ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Using the maximum as the upper limit is not prohibited, it is just not advised if you plan to plot the neighbour relationships on a map. The above for identifying neighbours are partially taken from the very well written, well-descriptive and thorough spdep package vignette for neighbours identification. 3.2.5.4 Adding spatial weights The neighbour lists can be supplemented with spatial weights using the nb2listw and nb2listwdist function from spdep package for the chosen type and coding scheme style. There are 6 different coding scheme styles that can be used to weigh neighbour relationships: B: is the basic binary coding (1 for neighbour, 0 for no neighbour). W: is row standardised (sums over all links to n). C: is globally standardised (sums over all links to n). U: is equal to C divided by the number of neighbours (sums over all links to unity). S: is the variance-stabilizing coding scheme (sums over all links to n). minmax: divides the weights by the minimum of the maximum row sums and maximum column sums of the input weights; It is similar to the C and U styles. The coding scheme style is practically the value each neighbour will get. For example, in a binary coding scheme style (B) if a spot is a neighbour of the spot in focus then gets the value of 1, else gets 0. Another example, in a row standardised coding scheme style (W) if the spot in focus has a total of 10 neighbours and each neighbour has a weight of 1, then the sum of all neighbour weights is 10, and each neighbour will get a normalised weight of 1/10 = 0.1. As a result, in the row standardised coding scheme, spots with many neighbours will have neighbours with lower weights and thus will not be over-emphasised. Starting from a binary neighbours list, in which regions are either listed as neighbours or are absent (thus not in the set of neighbours for some definition), we can add a distance-based weights list. The nb2listwdist function supplements a neighbours list with spatial weights for the chosen types of distance modelling and coding scheme. While the offered coding schemes parallel those of the nb2listw function above, three distance-based types of weights are available: inverse distance weighting (IDW), double-power distance weights (DPD), and exponential distance decay (EXP). The three types of distance weight calculations are based on pairwise distances 𝑑𝑖𝑗, all of which are controlled by parameter “alpha” (𝛼 below): idw: 𝑤𝑖𝑗=𝑑−𝛼𝑖𝑗, exp: 𝑤𝑖𝑗=exp(−𝛼⋅𝑑𝑖𝑗), dpd: 𝑤𝑖𝑗=[1−(𝑑𝑖𝑗/𝑑max)𝛼]𝛼, the latter of which leads to 𝑤𝑖𝑗=0 for all 𝑑𝑖𝑗&gt;𝑑max. Note that IDW weights show extreme behaviour close to 0 and can take on the value infinity. In such cases, the infinite values are replaced by the largest finite weight present in the weights list. The default coding scheme for nb2listwdist is “raw”, which outputs the raw distance-based weights without applying any kind of normalisation. In addition, the same coding scheme styles that are also available in the nb2listw function can be chosen. Below we will use only the nb2listwdist function which can accommodate both weight types and coding scheme styles. ## Set centroids as default geometry st_geometry(polygons) &lt;- &quot;geom_cntd&quot; ## Add weights nb_adjc_w &lt;- nb2listwdist(nb_adjc, polygons, type = &quot;idw&quot;, style = &quot;W&quot;, zero.policy = TRUE) ## Have a look nb_adjc_w$weights[1:5] ## [[1]] ## NULL ## ## [[2]] ## [1] 0.3344222 0.3333309 0.3322469 ## ## [[3]] ## [1] 0.5001435 0.4998565 ## ## [[4]] ## [1] 0.3339962 0.3330975 0.3329063 ## ## [[5]] ## [1] 0.2506436 0.2495468 0.2498330 0.2499765 3.2.6 Generate distance matrices A distance matrix is a mirrored matrix that contains the distance between a spot and every other spot. This distance can be a simple Euclidean distance based on the coordinates of the spots or a weighted distance according to a bandwidth around each spot using a kernel that gives higher scores to distances between spots that are closer together compared to the ones that are farther away. These weighted distance matrices are later used to run geographically weighted (GW) models. There are 6 different kernels that can be used to weight the distances between spots. The next two figures are from the GWmodel’s publication (Gollini et al. 2015) and provide a bit more description on that. Figure 3.2: The math equations that define the kernels. Figure 3.3: Examples from using each kernel. ## Set centroids as default geometry st_geometry(polygons) &lt;- &quot;geom_cntd&quot; ## Get Euclidean distances between spots dist.Mat &lt;- gw.dist(dp.locat = st_coordinates(polygons), p = 2) rownames(dist.Mat) &lt;- nb_names colnames(dist.Mat) &lt;- nb_names dist.Mat[1:5, 1:4] ## AAACTAACGTGGCGAC.1 GACTAAGATCATGCAC.1 ATCGACTCTTTCCGTT.1 ## AAACTAACGTGGCGAC.1 0.0000 195.257504 172.91415 ## GACTAAGATCATGCAC.1 195.2575 0.000000 24.92464 ## ATCGACTCTTTCCGTT.1 172.9142 24.924643 0.00000 ## TGGTTCGTAGCAAAGG.1 189.6205 6.224242 18.70041 ## GCTCTAAACCCTGACG.1 183.7097 16.504279 10.80228 ## TGGTTCGTAGCAAAGG.1 ## AAACTAACGTGGCGAC.1 189.620541 ## GACTAAGATCATGCAC.1 6.224242 ## ATCGACTCTTTCCGTT.1 18.700407 ## TGGTTCGTAGCAAAGG.1 0.000000 ## GCTCTAAACCCTGACG.1 10.818453 ## Set bandwidth bw = (range(dist.Mat)[2])/2 bw ## [1] 165.0985 ## Select a kernel kernel = &quot;bisquare&quot; ## Calculate W distance matrix w &lt;- gw.weight(vdist = dist.Mat, bw = bw, kernel = kernel, adaptive = FALSE) rownames(w) &lt;- nb_names colnames(w) &lt;- nb_names w[1:5, 1:4] ## AAACTAACGTGGCGAC.1 GACTAAGATCATGCAC.1 ATCGACTCTTTCCGTT.1 ## AAACTAACGTGGCGAC.1 1 0.0000000 0.0000000 ## GACTAAGATCATGCAC.1 0 1.0000000 0.9549366 ## ATCGACTCTTTCCGTT.1 0 0.9549366 1.0000000 ## TGGTTCGTAGCAAAGG.1 0 0.9971594 0.9745052 ## GCTCTAAACCCTGACG.1 0 0.9801134 0.9914563 ## TGGTTCGTAGCAAAGG.1 ## AAACTAACGTGGCGAC.1 0.0000000 ## GACTAAGATCATGCAC.1 0.9971594 ## ATCGACTCTTTCCGTT.1 0.9745052 ## TGGTTCGTAGCAAAGG.1 1.0000000 ## GCTCTAAACCCTGACG.1 0.9914308 3.2.7 Putting it all together The below code puts all these steps in order by selecting one of the options at each step. ## Load data and metadata inputD &lt;- readRDS(file = &quot;./data/hsLivSteat_JBO019_inputD.rds&quot;) inputMD &lt;- readRDS(file = &quot;./data/hsLivSteat_JBO019_inputMD.rds&quot;) ## Create point geometries spot_position &lt;- inputMD %&gt;% select(c(&quot;Barcode&quot;, &quot;pixel_x&quot;, &quot;pixel_y&quot;, &quot;Section&quot;)) centroids &lt;- spot_position %&gt;% st_as_sf(coords = c(&quot;pixel_x&quot;, &quot;pixel_y&quot;), remove = FALSE) ## Tessellate space cntd_union &lt;- st_union(centroids) voronoi &lt;- st_voronoi(cntd_union, bOnlyEdges = TRUE) voronoi_env &lt;- st_intersection(st_cast(voronoi), st_convex_hull(cntd_union)) ## Polygonise tessellation polygons &lt;- st_polygonize(voronoi_env) %&gt;% st_cast() %&gt;% st_sf() %&gt;% st_join(., centroids[centroids$Section == 1,], join = st_contains, left = FALSE) %&gt;% dplyr::rename(geom_pol = geometry) %&gt;% mutate(Barcode_rn = Barcode) %&gt;% column_to_rownames(&quot;Barcode_rn&quot;) %&gt;% st_sf() ## Update the polygon object to keep the centroid geometries as well polygons &lt;- polygons %&gt;% left_join(as.data.frame(centroids)) %&gt;% dplyr::rename(geom_cntd = geometry) %&gt;% st_sf(sf_column_name = &quot;geom_pol&quot;) ## Joining with `by = join_by(Barcode, pixel_x, pixel_y, Section)` ## Identify neighbours by Sphere Of Influence st_geometry(polygons) &lt;- &quot;geom_cntd&quot; nb_tri &lt;- tri2nb(polygons$geom_cntd, row.names = nb_names) nb_soi &lt;- graph2nb(soi.graph(nb_tri, polygons$geom_cntd), row.names = nb_names) nb_soi_w &lt;- nb2listwdist(nb_soi, polygons, type = &quot;idw&quot;, style = &quot;W&quot;, zero.policy = TRUE) ## Generate distance matrix dist.Mat &lt;- gw.dist(dp.locat = st_coordinates(polygons), p = 2) rownames(dist.Mat) &lt;- nb_names colnames(dist.Mat) &lt;- nb_names bw = (range(dist.Mat)[2])/2 kernel = &quot;bisquare&quot; dist.Mat.w &lt;- gw.weight(vdist = dist.Mat, bw = bw, kernel = kernel, adaptive = FALSE) ## Plot on tissue polygons ggplot(data = polygons) + geom_sf(aes(geometry = geom_pol)) + theme_void() ## Plot neighbour graph ggplot() + geom_sf(data = polygons, aes(geometry = geom_pol), colour = &quot;grey30&quot;, fill = &quot;white&quot;) + geom_sf(data = as(nb2lines(nb_soi, coords = polygons$geom_cntd), &quot;sf&quot;), colour = &quot;black&quot;, linewidth = 0.25) + geom_sf(data = polygons, aes(geometry = geom_cntd), colour = &quot;black&quot;, size = 1) + theme_void() References "],["practical-session-4.html", "Chapter 4 Practical session 4 4.1 Geographically Weighted Principal Components Analysis (GWPCA) 4.2 Load packages 4.3 Load Quality Controled and Normalised data 4.4 Data prearation and single GWPCA run 4.5 Run GWPCA 4.6 Plot global PCA results 4.7 Identify the leading genes in each location 4.8 Percentage of Total Variation (PTV) 4.9 Identify discrepancies", " Chapter 4 Practical session 4 In this session we will have a hands-on exploration of GW-PCA and its application to STx data. What can we learn from this novel technique? 4.1 Geographically Weighted Principal Components Analysis (GWPCA) A standard PCA can pick out the key multivariate modes of variability in the data. Looking at outlying values of the principal components of these data gives us an idea of unusual sites (in terms of combinations of gene expression profiles -and to a certain extend of combinations of cell types in each spot). Next, Geographically weighted PCA can be used to find spatial multivariate outliers. Sounds complicated, but really all this means is it identifies sites that have an unusual multi-way combination of gene expression in relation to their immediate geographical neighbours. It might be that the values observed at these sites as a combination is not uncommon in the tissue as a whole - but is very unusual in its locality. To find such outliers the procedure is relatively simple - instead of doing a PCA on the tissue as a whole, for each sample we do a PCA on data falling into a window centred on the location of that spot. In that way we can check whether the spot is like its neighbours or not, from a multivariate viewpoint. The following code carries out a geographically weighted PCA. In short, it runs a ‘windowed’ PCA around each of the spots. 4.2 Load packages 4.3 Load Quality Controled and Normalised data vars = top_hvgs[1:500] bw = 6*sfe@metadata[[&quot;spotDiameter&quot;]][[&quot;JBO019&quot;]][[&quot;spot_diameter_fullres&quot;]] k = 20 kernel = &quot;gaussian&quot; p = 1 adaptive = FALSE cv = TRUE scores = FALSE robust = FALSE # cc &lt;- availableCores() - 1 my.cl &lt;- parallel::makeCluster(availableCores() - 1, type = &#39;FORK&#39;) # &gt;&gt;&gt; it returns an error when inside the markdown. Maybe run with verbose = FALSE pcagw_ste &lt;- gwpca.ste(obj = sfe, assay = &quot;counts&quot;, vars = vars, p = p, k = k, bw = bw, kernel = kernel, adaptive = adaptive, scores = scores, robust = robust, cv = cv, future = FALSE, strategy = &quot;cluster&quot;, workers = my.cl, verbose = FALSE) ## ------------------------------------------------------ ## Future parallel strategy: cluster ## Number of cores to be used: 63/64 ## ------------------------------------------------------ ## Currently using doFuture [1.0.0] ## A backend is registered ## Running with 63 worker(s) ## Locations to iterate over: 1168 ## Please be patient. This will take a while... ## E.T.A. is approximatelly: 38.933 minutes ## Sit back and relax!! :) ## Performing Cross-Validation for selected bandwith 882.089951902194 ## Running GWPCA is done! ## Time elapsed: 1.823 mins plotGWPCA_global(gwpca = pcagw_ste, comps = 1:10, type = &quot;scree&quot;, point_args = list(size = 5, colour = &quot;red&quot;), line_args = list(linewidth = 2, colour = &quot;dodgerblue&quot;)) pcagw_ste &lt;- gwpca_LeadingGene(gwpca = pcagw_ste, sfe = sfe, pc_nos = 1:4, type = &quot;single&quot;, names = &quot;gene_names&quot;) ## 1 leading genes found for PC1 ## The leading genes in PC1 are: ## ALB ## 1168 ## 3 leading genes found for PC2 ## The leading genes in PC2 are: ## CYP2E1 FTL HP ## 315 138 715 ## 5 leading genes found for PC3 ## The leading genes in PC3 are: ## CES1 CYP2E1 FTL HP MT1G ## 95 144 270 639 20 ## 9 leading genes found for PC4 ## The leading genes in PC4 are: ## ADH1B CES1 CYP2E1 FGA FGB FTL HP MT1G ORM1 ## 1 25 194 37 4 705 16 169 17 pcagw_ste &lt;- gwpca_LeadingGene(gwpca = pcagw_ste, sfe = sfe, pc_nos = 1:4, genes_n = 4, type = &quot;multi&quot;, method = &quot;membership&quot;, names = &quot;gene_names&quot;) ## The number of individual leading genes groups found for PC1 is: 10 ## These groups are: ## ALB;CES1;CYP2E1;HP ALB;CYP2E1;FGA;HP ALB;CYP2E1;FTL;HP ALB;CYP2E1;HP;MT1G ## 2 1 220 16 ## ALB;FGA;FTL;HP ALB;FGA;HP;MT1G ALB;FGA;HP;ORM1 ALB;FTL;HP;MT1G ## 22 159 58 450 ## ALB;FTL;HP;ORM1 ALB;HP;MT1G;ORM1 ## 3 237 ## The number of individual leading genes groups found for PC2 is: 34 ## These groups are: Too many to print them! ## The number of individual leading genes groups found for PC3 is: 41 ## These groups are: Too many to print them! ## The number of individual leading genes groups found for PC4 is: 112 ## These groups are: Too many to print them! plotGWPCA_leadingG(gwpca = pcagw_ste, comps = 1:4, type = &quot;single&quot;, arrange = TRUE) ## Plots arranged in a 2x2 panel. ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] plotGWPCA_leadingG(gwpca = pcagw_ste, comps = 1:4, type = &quot;multi&quot;, arrange = TRUE) ## Plots arranged in a 2x2 panel. ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] 4.3.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1 # countsNormCenter &lt;- readRDS(file = &quot;./data/countsNormScaled.rds&quot;) # rowDATA &lt;- readRDS(file = &quot;./data/rowDATA.rds&quot;) # colDATA &lt;- readRDS(file = &quot;./data/colDATA.rds&quot;) We imported 3 tables: countsNormCenter: normalised and centred and scaled counts for the top HVGs without mitochondrial genes. We followed the preprocessing steps from practical session 2. rowDATA: Gene annotations (containing, amongst others, ENSG IDs and gene names). colDATA: Metadata for the spots that passed the QC as in practical session 2. Because gwpca uses princomp to run the PCAs and this does not accept the number of variables (genes) being more than the number of samples (spots). 4.4 Data prearation and single GWPCA run ## Prepare for Geographically Weighted PCA (GWPCA) countsNormCenter &lt;- countsNormCenter %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;rowname&quot;) %&gt;% arrange(&quot;rowname&quot;) %&gt;% column_to_rownames(&quot;rowname&quot;) ## Get the coordinates coords &lt;- colDATA[, c(&quot;Barcode&quot;, &quot;pixel_x&quot;, &quot;pixel_y&quot;)] %&gt;% arrange(Barcode) %&gt;% column_to_rownames(var = &quot;Barcode&quot;) ## Get the data into a SpatialPointsDataFrame object inputPCAgw &lt;- SpatialPointsDataFrame(coords, countsNormCenter, match.ID = TRUE) ## Get the gene names that are going to be evaluated vars &lt;- colnames(inputPCAgw@data) ## Set the number of components to be retained k &lt;- 20 ## Set the kernel to be used kernel = &quot;gaussian&quot; ## Set a bandwidth -in pixels- for neighbourhood dist.Mat &lt;- gw.dist(dp.locat = st_coordinates(colDATA$geom_cntd), p = 1) The bandwidth is essentially the radius around each spot where every other spot that falls inside it is considered a neighbour. We can set bandwidth as a fixed value or we can select the bandwidth automatically. Without going into detail here, this is achieved by a form of cross validation, where each observation is omitted, and it is attempted to reconstruct the values on the basis of principal components, derived from the other observations. The bandwidth achieving the optimal results is the one selected. For a complete explanation, see Harris, Brunsdon, and Charlton (2011). The function bw.gwpca computes this: # bw.choice &lt;- bw.gwpca(inputPCAgw, # vars = vars, # k = k, # kernel = kernel, # dMat = dist.Mat, # adaptive = TRUE) # # ## Save # saveRDS(bw.choice, file = &quot;./data/bw.choice.rds&quot;) Since this command computes several GWPCA estimates at different bandwidths in order to find an optimum, it will take noticeably longer than the version of the function with a prescribed bandwidth. Once run, gwpca is re-run with the bandwidth set to bw.choice. Below load the bw.choice object we already calculated for you: bw.choice &lt;- readRDS(file = &quot;./data/bw.choice.rds&quot;) NOTE: Larger bandwidths imply bigger moving spatial windows, which in turn imply smoother spatially varying outputs. 4.5 Run GWPCA Run the optimised GWPCA with the automatically estimated bandwidth: begin_pca &lt;- Sys.time() pcaGW &lt;- gwpca(inputPCAgw, vars = vars, bw = bw.choice, k = k, dMat = dist.Mat, adaptive = TRUE, kernel = kernel) end_pca &lt;- Sys.time() time_pca &lt;- difftime(end_pca, begin_pca) print(time_pca) # saveRDS(pcaGW, file = &quot;./data/pcaGW.rds&quot;) Because GWPCA can take some time to run, we ran it for you and below you can load the output: # pcaGW &lt;- readRDS(file = &quot;./data/pcaGW.rds&quot;) 4.6 Plot global PCA results In the next steps we will be looking inside the output from gwpca function and we are going to extract some basic information. Since GWPCA is multiple local PCAs, it is good to know how many PCs makes sense to look at. We can do so by running a global PCA and plotting a scree plot: ## Prepare data for scree plot pvar &lt;- pcaGW.noncentred$pca$sdev^2/sum(pcaGW.noncentred$pca$sdev^2)*100 pvar &lt;- data.frame(var = pvar, PCs = sprintf(&quot;PC%02d&quot;, seq(1, length(pvar)))) ## Plot scree plot ggplot(pvar[1:10,], aes(x = PCs, y = var, group = 1)) + geom_point(size = 3) + geom_line() + xlab(&quot;Principal Component&quot;) + ylab(&quot;% Variance Explained&quot;) + ggtitle(&quot;Scree Plot&quot;) + ylim(0, 5) + theme_classic() In a Principal Component Analysis (PCA), the first three principal components may explain less than 15% of the variance in the data if the data is highly dispersed or if there is a large amount of noise in the data. This means that the first three principal components are not capturing a significant portion of the variability in the data. This could be due to a lack of clear structure in the data or a lack of meaningful patterns that can be captured by the PCA. Alternatively, it could be due to the presence of many irrelevant features or variables in the data that are not contributing to the overall variance. 4.7 Identify the leading genes in each location ## Load biomart biomartHumanGRCh37 &lt;- readRDS(file = &quot;./data/biomartHumanGRCh37.rds&quot;) ## Extract leading genes lead.item &lt;- gwpca.Leading.G.single(pcaGW.noncentred, pc.no = 1, sf.geom = colDATA$geom_pol, gene.names = TRUE, biomart = biomartHumanGRCh37, check.names = FALSE) pc.No = 1 col.No &lt;- length(unique(lead.item[,1])) colour.values &lt;- get.colours(col.No) ggplot() + geom_sf(data = lead.item$geometry, aes(fill = lead.item[,1])) + scale_fill_manual(values = colour.values) + xlab(&quot;X coordinates (pixels)&quot;) + ylab(&quot;Y coordinates (pixels)&quot;) + labs(title = paste0(&quot;Leading Genes on PC&quot;, pc.No), fill = &quot;Leading Genes&quot;) + theme_void() + theme(legend.position = &quot;none&quot;) 4.8 Percentage of Total Variation (PTV) Another useful diagnostic for PCA is the percentage of variability in the data explained by each of the components. This can be achieved by looking at the var component of pcaGW; this is written as pcaGW$var. This is an XXXX by XX matrix - where XXXX is the number of observations and XX is the number of components. For each location, the XX columns correspond to the variance of each of the principal components. Looking at the proportion of each component in the sum of all of the variances shows how much of the variability in the data each component contributes. If, say, the first two components contributed 90% of the total variance, then it is reasonable to assume that much of the variability in the data can be seen by just looking at these two components. Because this is geographically weighted PCA, however, this quantity varies across the map. ## Calculate the PTV for multiple Components props &lt;- gwpca.prop.var(gwpca.obj = pcaGW, n.comp = c(5, 10, 20, 30, 40, 50), polygons = colDATA$geom_pol) ## Map PTV for (i in c(5, 10, 20, 30)) { comps &lt;- sprintf(&quot;Comps_%02d&quot;, i) ptv.map &lt;- dplyr::select(props, all_of(c(comps, &quot;geometry&quot;))) (ggplot() + geom_sf(data = ptv.map$geometry, aes(fill = ptv.map[,1])) + scale_fill_viridis_c(option = &quot;inferno&quot;, limits = c(0, 100)) + labs(title = &quot;Percantage of Total Variation\\n(PTV)&quot;, fill = paste0(&quot;PTV of &quot;, i, &quot;\\n components&quot;)) + theme_void() + theme(legend.position = &quot;right&quot;)) %&gt;% print() } 4.9 Identify discrepancies Global PCA can be used to identify multivariate outliers. Extending this, it is also possible to use local PCA (i.e., GWPCA) to identify local outliers. One way of doing this links back to the cross-validation idea used earlier to select a bandwidth. Recall that this is based on a score of how well each observation can be reconstructed on the basis of local PCs. The score measures the total discrepancies of true data values from the reconstructed ones - and the bandwidth chosen is the one minimising this. However, the total discrepancy score is the sum of the individual discrepancies. A very large individual discrepancy associated with an observation suggests it is very different - in a multidimensional way, to the observations near to it. These discrepancies can be calculated with the gwpca.cv.contrib function. ## Calculate the discrepancies data.mat &lt;- as.matrix(inputPCAgw@data) discrepancy &lt;- gwpca.cv.contrib(data.mat, coordinates(inputPCAgw), bw = bw.choice, adaptive = TRUE, dMat = dist.Mat) discrepancy_df &lt;- data.frame(disc = discrepancy) ## Plot as boxplot ggplot(pivot_longer(discrepancy_df, col = &quot;disc&quot;), aes(x = name, y = value)) + geom_boxplot(fill = &quot;#D1E5F0&quot;, colour = &quot;#2166AC&quot;, outlier.colour = &quot;red&quot;, outlier.size = 2) + geom_jitter(col = &quot;#EF8A62&quot;, size = 2, width = 0.3, alpha = 0.8) + # add horizontal line geom_hline(yintercept = c(2e+04, 1.8e+05), linetype = &quot;dashed&quot;, color = &quot;royalblue&quot;) + # customise axes scale_x_discrete(labels = &quot;Locations&quot;) + coord_flip() + xlab(NULL) + ylab(&quot;Local PC Discrepancy&quot;) + theme_classic() + theme(axis.text.y = element_text(angle = 90, hjust = 0.5)) Comment on the discrepancies and the Liver histopathology ## Plot map dt &lt;- inputPCAgw@data %&gt;% mutate(disc = discrepancy, geometry = colDATA$geom_pol) disc.map &lt;- dplyr::select(dt, all_of(c(&quot;disc&quot;, &quot;geometry&quot;))) ggplot() + geom_sf(data = disc.map$geometry, aes(fill = disc.map$disc)) + scale_fill_viridis_c(option = &quot;inferno&quot;) + labs(title = &quot;Local PC Discrepancy&quot;, fill = &quot;Discrepancy\\nscore&quot;) + theme_void() + theme(legend.position = &quot;right&quot;) Another possibility to understand the nature of the outlier is a parallel coordinates heatmap. Here, each observation neighbouring the location that has been found to be an outlier is shown as a column with the genes in rows. Since here we are investigating local outliers, one particular observation is highlighted in red -the outlier-, and the remaining ones in grey, but with the intensity of the grey fading according to their distance from the red observation. This enables you to see what characteristic the red observation has that means it as outlying from its neighbours. The plot can be created using gw.pcplot: # Get the highest-scoring outliers outliers &lt;- which(discrepancy_df &gt; 1.8e+05) # Plot the heatmap to visualise the genes that make this location an outlier gwpca.plot.outlier(countsNormCenter, bw = bw.choice, focus = outliers[1], dMat = dist.Mat, show.vars = &quot;top&quot;, mean.diff = 1, gene.names = TRUE, biomart = biomartHumanGRCh37, show.data = FALSE, check.names = FALSE, scale = &quot;row&quot;, color = rev(colorRampPalette(brewer.pal(11, &quot;RdBu&quot;))(1000))) References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
